{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------------========\n",
    "PROJECT'S TITLE\n",
    "    DATA SCIENTIST PROJECT RELATED TO THE ANALYSIS OF HOSPITALIZATION\n",
    "     DATA IN FRANCE DUE TO COVID-19.\n",
    "\n",
    "\n",
    "PROJET/PURPOSE:\n",
    "    The UDACITY DATA SCIENTIST CAPSTONE project consists in building\n",
    "     a data science project of my choice with two deliverables:\n",
    "      - A Github repository of my work;\n",
    "      - A blog post written for the audience.\n",
    "\n",
    "    Considering the rebound of COVID-19 cases in France these last\n",
    "     weeks, I decided to analyze data of COVID-19 progress in France\n",
    "     with figures directly reported by the hospitals via an\n",
    "     institutional site.\n",
    "\n",
    "    The blog post introduce the context of my study, the purpose of\n",
    "     my study and a strategy to address it.\n",
    "    To sum up, it will work on data sets to be able to forecast the \n",
    "     number of hospitalizations in a context of COVID-19 pandemy for\n",
    "     the departement of Haute-Garonne (Region Occtinanie, France).\n",
    "\n",
    "    This notebook allows:\n",
    "     - Analyzing the data (data exploration and vizualization);\n",
    "     - Propose a methodology for prepare the data set by \n",
    "        preprocessing data and deepen understanding of these data\n",
    "        and finally kept the final data set;\n",
    "     - Select the modeling method with related metrics and find out\n",
    "        ways to improve this method.\n",
    "\n",
    "The notebook here-below gathers my work for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANALYSIS - Data exploration - import libraries\n",
    "# ----------------------------------------------------------------------========\n",
    "\n",
    "import sys\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "from IPython.display import SVG\n",
    "from plotly.subplots import make_subplots\n",
    "# import pyplot\n",
    "# ERROR: Could not find a version that satisfies the requirement pyplot\n",
    "#        (from versions: none)\n",
    "#        No matching distribution found for pyplot\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import linear_model\n",
    "from sklearn import neighbors\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import top_k_accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "# from sklearn.metrics import jaccard_similarity_score\n",
    "# ImportError: cannot import name 'jaccard_similarity_score' from\n",
    "#  'sklearn.metrics'\n",
    "\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingRandomSearchCV\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "# requires installing\n",
    "# https://gtk-win.sourceforge.io/home/index.php/Main/Downloads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANALYSIS - Data exploration - describe in the input files\n",
    "# ----------------------------------------------------------------------========\n",
    "\n",
    "I've gathered several data files reporting various information related\n",
    " to the epidemic of COVID-19 in France from the institutional web site:\n",
    " https://www.data.gouv.fr/fr/datasets\n",
    "\n",
    "The source web site indicates that data have been gathered along the\n",
    " time from various formats and contents.\n",
    "\n",
    "All the files used are under the License \"Open Data Commons Open\n",
    " Database License (ODbL)\". \n",
    "\n",
    "I downloaded the following data files the 29 December 2022. All data are\n",
    " stored in Github of this project.\n",
    "\n",
    "\n",
    "FILE # 1\n",
    "\n",
    "- Initial name: \"donnees-vaccination-par-tranche-dage-type-de-vaccin-et\n",
    "                 -departement.csv\"\n",
    "\n",
    "- New name: \"COVID-19_France_data_vaccin_population.csv\"\n",
    "\n",
    "- Steady URL: \"https://www.data.gouv.fr/fr/datasets/donnees-vaccination-\n",
    "               par-tranche-dage-type-de-vaccin-et-departement-region/\"\n",
    "\n",
    "- Last update: 13-Dec-2022\n",
    "\n",
    "- License ID: 60bdce49abcc8f5dcb2fcb3b\n",
    "\n",
    "- Brief description: Vaccination data by age bracket, type of vaccine\n",
    "                     and department / region.\n",
    "\n",
    "- Size: 146 Mb\n",
    "\n",
    "\n",
    "FILE #2\n",
    "\n",
    "- Initial name: \"donnees-vaccination-par-pathologie.csv\"\n",
    "\n",
    "- New name: \"COVID-19_France_data_vaccin_pathology.csv\"\n",
    "\n",
    "- Steady URL: \"https://www.data.gouv.fr/fr/datasets/donnees-vaccination-\n",
    "               par-pathologie-et-departement-region/\"\n",
    "\n",
    "- Last update: 13-Dec-2022\n",
    "\n",
    "- License ID: 60bdce48e306a187d32ee2c1\n",
    "\n",
    "- Brief description: Vaccination data per pathology and department\n",
    "                     / region.\n",
    "\n",
    "- Size: 1.2 Mb\n",
    "\n",
    "\n",
    "FILE #3\n",
    "\n",
    "- Initial name: \"table-indicateurs-open-data-dep-2022-12-28-19h00.csv\"\n",
    "\n",
    "- New name: \"COVID-19_France_data_epidemic_indicators.csv\"\n",
    "\n",
    "- Steady URL: \"https://www.data.gouv.fr/fr/datasets/synthese-des-\n",
    "               indicateurs-de-suivi-de-lepidemie-covid-19/\"\n",
    "\n",
    "- Last update: 28-Dec-2022\n",
    "\n",
    "- License ID: 60190d00a7273a8100dd4d38\n",
    "\n",
    "- Brief description: COVID-19 epidemic monitoring indicators summary\n",
    "\n",
    "- Size: 11.2 Mb\n",
    "\n",
    "\n",
    "FILE #4\n",
    "\n",
    "- Initial name: \"vacsi-dep-2022-12-28-19h00.csv\"\n",
    "\n",
    "- New name: \"COVID-19_France_data_vaccin_indicators.csv\"\n",
    "\n",
    "- Steady URL: \"https://www.data.gouv.fr/fr/datasets/r/735b0df8-51b4-\n",
    "               4dd2-8a2d-8e46d77d60d8\"\n",
    "\n",
    "- Last update: 28-Dec-2022\n",
    "\n",
    "- License ID: 6010206e7aa742eb447930f7\n",
    "\n",
    "- Brief description: Data related to people vaccinated against COVID-19\n",
    "                   per department.\n",
    "\n",
    "- Size: 6.2 Mb\n",
    "\n",
    "\n",
    "FILE #5\n",
    "\n",
    "- Initial name: \"vacsi-tot-dep-2022-12-28-19h00.csv\"\n",
    "\n",
    "- New name: \"COVID-19_France_data_vaccin_indicators_tot.csv\"\n",
    "\n",
    "- Steady URL: \"https://www.data.gouv.fr/fr/datasets/r/7969c06d-848e-\n",
    "               40cf-9c3c-21b5bd5a874b\"\n",
    "\n",
    "- Last update: 28-Dec-2022\n",
    "\n",
    "- License ID: 6010206e7aa742eb447930f7\n",
    "\n",
    "- Brief description: Data related to cumulative people vaccinated \n",
    "                     against COVID-19 per department.\n",
    "\n",
    "- Size: 10 Kb\n",
    "\n",
    "\n",
    "COMMENT:\n",
    "\n",
    "Data file were renamed to avoid being dependent of the date that may be\n",
    " notified in the file's name and to simplify and gather the designation\n",
    " of these files in the workspace.\n",
    "\n",
    "\n",
    "All these files are known to be of type 'txt/csv'. They are fulfilled \n",
    " in french such that I was required to open these files under Unicode\n",
    " UTF-8 format.\n",
    "\n",
    "\n",
    "Let's explore these files through the notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANALYSIS - Data exploration - Workspace\n",
    "# ----------------------------------------------------------------------========\n",
    "\n",
    "# Purpose: Define the main directory of the data files: 'work_dir'\n",
    "# Instruction: Modify value of 'work_dir' according to your workspace.\n",
    "dir_1 = r\"C:\\Users\\to202835\\OneDrive - ATR\\_exploitation\\formation\"\n",
    "dir_2 = r\"\\2023\\Udacity_DataScience\\project_capstone_v1.4.0\"\n",
    "work_dir = dir_1 + dir_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANALYSIS - Data exploration - Workspace\n",
    "# ----------------------------------------------------------------------========\n",
    "\n",
    "# Purpose: Build a function that read input csv files\n",
    "# Discussion: Though some of the used data files are also available in\n",
    "#             json format, I prefered get all my data files in the same\n",
    "#             format to ease the read.\n",
    "\n",
    "def read_csv(filename,\n",
    "             dtype_values={},\n",
    "             filedir=work_dir,\n",
    "             separator=',',\n",
    "             encod_errors='ignore'):\n",
    "    '''\n",
    "    DESCRIPTION\n",
    "        Read input csv files\n",
    "    INPUT\n",
    "        filename (string) is the name of the data file to read;\n",
    "        dtype_values (dictionary) is the set of information to enforce\n",
    "                     read of selected columns in a given format to \n",
    "                     possibly avoid warning message of Low memory:\n",
    "                     default = none;\n",
    "        filedir=work_dir (string) is the path of the data files \n",
    "                         directory.\n",
    "                         default = work_dir (previously defined)\n",
    "    OUTPUT\n",
    "        df (pandas dataframe) is the dataframe resulting from the read\n",
    "           of the input data file. If the read fails, it returns an \n",
    "           empty dataframe.\n",
    "    '''\n",
    "\n",
    "    # Build the complete file path\n",
    "    filepath = \"\\\\\".join((filedir, filename))\n",
    "\n",
    "    # trying read the csv data file\n",
    "    try:\n",
    "        df = pd.read_csv(filepath.replace('\\\\','/'),\n",
    "             dtype=dtype_values, sep=separator,\n",
    "             encoding_errors=encod_errors,\n",
    "             low_memory=False)\n",
    "        print(\"- Opening '{}'\".format(filename))\n",
    "    except:\n",
    "        df = pd.DataFrame([])\n",
    "        print(\"- Unable to open '{}'\".format(filename))\n",
    "        raise\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANALYSIS - Data exploration - access the data\n",
    "# ----------------------------------------------------------------------========\n",
    "\"\"\"\n",
    "DISCUSSION\n",
    "    Initial read of the file report an issue on format of column #2\n",
    "     that causes a low memory warning. The issue was solved by setting\n",
    "     the appropriate format of some columns with mixed types \n",
    "     (identified after the initial opening and analysis of the file) and\n",
    "     by using separator \";\" except for file #3\n",
    "\"\"\"\n",
    "# List of names of all input data files to work on\n",
    "file_1 = r\"COVID-19_France_data_vaccin_population.csv\"\n",
    "file_2 = r\"COVID-19_France_data_vaccin_pathology.csv\"\n",
    "file_3 = r\"COVID-19_France_data_epidemic_indicators.csv\"\n",
    "file_4 = r\"COVID-19_France_data_vaccin_indicators.csv\"\n",
    "file_5 = r\"COVID-19_France_data_vaccin_indicators_tot.csv\"\n",
    "\n",
    "# Define the labels that require a change of format\n",
    "dtypes_1 = {'date_reference': str,\n",
    " 'semaine_injection': str,\n",
    " 'region_residence': str,\n",
    " 'libelle_region': str,\n",
    " 'departement_residence': str,\n",
    " 'libelle_departement': str,\n",
    " 'classe_age': str,\n",
    " 'libelle_classe_age': str,\n",
    " 'type_vaccin': str,\n",
    " 'date': str}  # These columns have a mixed type of data\n",
    "dtypes_2 = {}\n",
    "dtypes_3 = {\"date\": str,\n",
    "          \"dep\": str,\n",
    "          \"lib_dep\": str,\n",
    "          \"lib_reg\": str}  # These columns have a mixed type of data\n",
    "dtypes_4 = {\"dep\": str}  # column 'dep' has mixed types. So I enforce\n",
    "                         #  the format while reading the csv file to\n",
    "                         #  avoid a low memory warning message.\n",
    "dtypes_5 = {\"dep\": str}  # column 'dep' has mixed types. So I enforce\n",
    "                         #  the format while reading the csv file to\n",
    "                         #  avoid a low memory warning message.\n",
    "\n",
    "files = dict()\n",
    "files['f1'] = {'filename': file_1, 'dtypes':dtypes_1, 'sep': ';'}\n",
    "files['f2'] = {'filename': file_2, 'dtypes':dtypes_2, 'sep': ';'}\n",
    "files['f3'] = {'filename': file_3, 'dtypes':dtypes_3, 'sep': ''}\n",
    "files['f4'] = {'filename': file_4, 'dtypes':dtypes_4, 'sep': ';'}\n",
    "files['f5'] = {'filename': file_5, 'dtypes':dtypes_5, 'sep': ';'}\n",
    "\n",
    "# Read the files and store data into dataframes\n",
    "df = pd.DataFrame()\n",
    "for f in files:\n",
    "    print(f)\n",
    "    if files[f]['sep'] == '':\n",
    "        df = read_csv(files[f]['filename'], dtype_values=files[f]['dtypes'])\n",
    "    else:\n",
    "        df = read_csv(files[f]['filename'], dtype_values=files[f]['dtypes'], separator=files[f]['sep'])\n",
    "    files[f]['df'] = df.copy(deep=True)\n",
    "    df.head()\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANALYSIS - Data exploration - access the data\n",
    "# ----------------------------------------------------------------------========\n",
    "\n",
    "# Get on view on file #1 data and push data into a dataframe\n",
    "df1 = files['f1']['df'].copy(deep=True)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANALYSIS - Data exploration - access the data\n",
    "# ----------------------------------------------------------------------========\n",
    "\n",
    "# Get on view on file #2 data and push data into a dataframe\n",
    "df2 = files['f2']['df'].copy(deep=True)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANALYSIS - Data exploration - access the data\n",
    "# ----------------------------------------------------------------------========\n",
    "\n",
    "# Get on view on file #3 data and push data into a dataframe\n",
    "df3 = files['f3']['df'].copy(deep=True)\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANALYSIS - Data exploration - access the data\n",
    "# ----------------------------------------------------------------------========\n",
    "\n",
    "# Get on view on file #4 data and push data into a dataframe\n",
    "df4 = files['f4']['df'].copy(deep=True)\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANALYSIS - Data exploration - access the data\n",
    "# ----------------------------------------------------------------------========\n",
    "\n",
    "# Get on view on file #5 data and push data into a dataframe\n",
    "df5 = files['f5']['df'].copy(deep=True)\n",
    "df5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANALYSIS - Data exploration - basic analysis of the data sets\n",
    "# ----------------------------------------------------------------------========\n",
    "\n",
    "# Build a function to analysis the type and availability of valid data.\n",
    "\n",
    "def display_columns_info(df):\n",
    "    '''\n",
    "    DESCRIPTION\n",
    "        Display some information per column related to the data set\n",
    "    INPUT\n",
    "        df is the dataframe\n",
    "    OUTPUT\n",
    "        nil (only display)    \n",
    "    '''\n",
    "    \n",
    "    # Measure length of the column's title only for presentation purpose\n",
    "    max_len = 0\n",
    "    cols = np.array(df.columns)\n",
    "    for c in cols:\n",
    "        if len(c) > max_len:\n",
    "            max_len = len(c)\n",
    "    size = max_len + 2  # I will create a regulat length for label field.\n",
    "\n",
    "    # Display information per column        \n",
    "    field_1 = \"column label\" + ' '*(size - 11)\n",
    "    field_size = 10\n",
    "    field_2 = \"      size \"\n",
    "    field_3 = \"      type \"\n",
    "    field_4 = \"   nb uniq  rate uniq \"\n",
    "    field_5 = \"    nb nan   rate nan \"\n",
    "    field_6 = \"    nb inf   rate inf \"\n",
    "    field_7 = \"     other \"\n",
    "    # Introducing the results\n",
    "    m = field_1 + field_2 + field_3 + field_4 + field_5 + field_6 + field_7\n",
    "    print(m)\n",
    "\n",
    "    # Then run along the columns to perform and give the analysis per column.\n",
    "    for col in cols:\n",
    "        # column's size\n",
    "        col_size = df[col].shape[0]\n",
    "        # get column's type        \n",
    "        col_type = df[col].dtypes\n",
    "        cot_typ = str(col_type)\n",
    "        # get number and rate of unique values\n",
    "        values_uniq = np.array(pd.unique(df[col]))\n",
    "        nb_uniq = len(values_uniq)\n",
    "        rate_uniq = 100 * nb_uniq / col_size\n",
    "        # get number and rate of nan values\n",
    "        nb_nan = df[col].isna().sum()\n",
    "        rate_nan = 100 * nb_nan / col_size\n",
    "        # get number and rate of infinite values\n",
    "        nb_inf = 0\n",
    "        mixed_types = []\n",
    "        # Run along values of the column\n",
    "        for value in np.array(df[col].values):\n",
    "            # Count infinite value\n",
    "            if (value == np.inf) or (value == -np.inf):\n",
    "                nb_inf += 1\n",
    "            # Check consistency of the value type with its column\n",
    "            if \" \" in str(type(value)):\n",
    "                val_type = str(type(value)).split(\"'\")[1]\n",
    "            else:\n",
    "                if \".\" in str(type(value)):\n",
    "                    val_type = str(type(value)).split(\".\")[1][:-1]\n",
    "                else:\n",
    "                    val_type = str(type(value))\n",
    "            if (val_type != cot_typ):\n",
    "                if val_type not in mixed_types:\n",
    "                    mixed_types.append(val_type)\n",
    "\n",
    "        # Compute the rate of infinite values in the column\n",
    "        rate_inf = 100 * nb_inf / col_size\n",
    "\n",
    "        # Report mixed types if any\n",
    "        msg_mixed_types = ''\n",
    "        if len(mixed_types) > 1:\n",
    "            msg_mixed_types = '\\tMixed types: ' + str(mixed_types)\n",
    "\n",
    "        # Check among 'date' values that they are all strings with a length\n",
    "        #  of 10.\n",
    "        mem_unexp_dates = []\n",
    "        msg_unexp_dates = ''\n",
    "        if col == 'date':\n",
    "            for value in values_uniq:\n",
    "                if (not isinstance(value, str)) or (len(value) != 10):\n",
    "                    mem_unexp_dates.append(value)\n",
    "            if len(mem_unexp_dates) > 0:\n",
    "                msg_unexp_dates = '\\tWrong date format: ' + str(mem_unexp_dates)\n",
    "\n",
    "        # Display result\n",
    "        dec = 2\n",
    "        print('{}{} {}{} {}{} {}{}{}{} % {}{}{}{} % {}{}{}{} % {} {}'.format(\n",
    "            col, ' '*(size - len(col)),\n",
    "            ' ' * (field_size - len(str(col_size))), col_size,\n",
    "            ' ' * (field_size - len(str(col_type))), col_type,\n",
    "            ' ' * (field_size - len(str(nb_uniq))), nb_uniq,\n",
    "            ' ' * (field_size -1 - len(str(round(rate_uniq, dec)))), round(rate_uniq, dec),\n",
    "            ' ' * (field_size - len(str(nb_nan))), nb_nan,\n",
    "            ' ' * (field_size -1 - len(str(round(rate_nan, dec)))), round(rate_nan, dec),\n",
    "            ' ' * (field_size - len(str(nb_inf))), nb_inf,\n",
    "            ' ' * (field_size -1 - len(str(round(rate_inf, dec)))), round(rate_inf, dec),\n",
    "            msg_unexp_dates,\n",
    "            msg_mixed_types)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANALYSIS - Data exploration - basic analysis of the data sets\n",
    "# ----------------------------------------------------------------------========\n",
    "# Vizualize information on file 1\n",
    "display_columns_info(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANALYSIS - Data exploration - basic analysis of the data sets\n",
    "# ----------------------------------------------------------------------========\n",
    "# According to the result, I will remove columns almost empty\n",
    "#  (at least 50% of nan):\n",
    "remove_list1 = ['effectif_cumu_1_inj', 'effectif_cumu_termine',\n",
    "         'taux_cumu_1_inj', 'taux_cumu_termine', 'effectif_1_inj',\n",
    "         'effectif_termine', 'taux_1_inj', 'taux_termine', \n",
    "         'effectif_rappel', 'effectif_cumu_rappel', \n",
    "         'effectif_rappel_parmi_eligible',\n",
    "         'effectif_eligible_au_rappel', 'taux_rappel',\n",
    "         'taux_cumu_rappel', 'taux_cumu_rappeleli']\n",
    "\n",
    "# Refer to the blog post for other comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANALYSIS - Data exploration - basic analysis of the data sets\n",
    "# ----------------------------------------------------------------------========\n",
    "# Vizualize information on file 2\n",
    "display_columns_info(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANALYSIS - Data exploration - basic analysis of the data sets\n",
    "# ----------------------------------------------------------------------========\n",
    "# Vizualize information on file 3\n",
    "display_columns_info(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANALYSIS - Data exploration - basic analysis of the data sets\n",
    "# ----------------------------------------------------------------------========\n",
    "# According to the result, remove these columns with a lot of missing\n",
    "#  data.\n",
    "remove_list3 = ['R', 'cv_dose1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANALYSIS - Data exploration - basic analysis of the data sets\n",
    "# ----------------------------------------------------------------------========\n",
    "# Vizualize information on file 4\n",
    "display_columns_info(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANALYSIS - Data exploration - basic analysis of the data sets\n",
    "# ----------------------------------------------------------------------========\n",
    "# According to the result, rename column 'jour' as 'date'\n",
    "renaming_4_dict = {'jour': 'date'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANALYSIS - Data exploration - basic analysis of the data sets\n",
    "# ----------------------------------------------------------------------========\n",
    "# Vizualize information on file 5\n",
    "display_columns_info(df5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANALYSIS - Data exploration - basic analysis of the data sets\n",
    "# ----------------------------------------------------------------------========\n",
    "# According to the result, rename column 'jour' as 'date' (idem for file #4)\n",
    "renaming_5_dict = {'jour': 'date'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.rename(renaming_4_dict, axis=1, inplace=True)\n",
    "df5.rename(renaming_5_dict, axis=1, inplace=True)\n",
    "# to be done before merging because it's a label to merge with\n",
    "# and before time series analysis, because it's based on 'date'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANALYSIS - Data exploration - Time series analysis\n",
    "# ----------------------------------------------------------------------========\n",
    "\n",
    "# Basically, I want to know how many unique dates owns every dataframe:\n",
    "df_list = [df1, df2, df3, df4, df5]\n",
    "print('Number of unique values of date per input data file:')\n",
    "for i, df in enumerate(df_list):\n",
    "    print(\"File #\", i+1, '\\t', len(np.unique(np.array(df['date']))))\n",
    "# note: Applying the function 'display_columns_info' give me already\n",
    "#  the same result but it allows to summarize it here.\n",
    "\n",
    "# Result: I see that merging all files would give me only one date.\n",
    "#         So I need to identify clearly the covering time period of\n",
    "#         every files to see which ones I could merge.\n",
    "#         A priori, I would keep only files 3 and 4, let's check that.\n",
    "#         Files 2 and 5 return only one date: ['2022-12-04']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANALYSIS - Data exploration - Time series analysis\n",
    "# ----------------------------------------------------------------------========\n",
    "\n",
    "# Build a generic function for displaying time series\n",
    "\n",
    "def plot_time_series(df, label: str, departments: list):\n",
    "    '''\n",
    "    DESCRIPTION\n",
    "        Plot a line chart of figures for the given label and the \n",
    "         selected list of departments.\n",
    "    INPUT\n",
    "        df is the pandas dataframe;\n",
    "        label (string) is the name of the column for which I want a\n",
    "              plot;\n",
    "        departments (list) is the list departments for which I want\n",
    "                    a plot.\n",
    "    OUTPUT\n",
    "        nil (only display)\n",
    "    '''\n",
    "\n",
    "    # If not already done, I group df by department and timestamp\n",
    "    # df.groupby(['dep', 'timestamp'])  # If no dummy applied\n",
    "    df.groupby(['dep', 'date'])  # If no dummy applied\n",
    "\n",
    "    # get the uniq list of the selected departments, just in case of...\n",
    "    departments = np.unique(departments)  # just in case of \n",
    "    \n",
    "    df_plot_list = []  # list to store data for plotting of every\n",
    "                       #  selected departments.\n",
    "    # Run along the list of departments\n",
    "    for dep in departments:\n",
    "        # Get the values of the label along the time\n",
    "        df_dep = pd.DataFrame([])\n",
    "        df_dep = df[df['dep'] == dep]\n",
    "\n",
    "        # Get the time for this dep:\n",
    "        x_val = np.array(df_dep['date'])\n",
    "        \n",
    "        # get the values of the label for this dep\n",
    "        y_val = np.array(df_dep[label])\n",
    "\n",
    "        # Create a dataframe for the plot\n",
    "        df_plot = pd.DataFrame(dict(x = x_val, y = y_val))\n",
    "\n",
    "        # store the data for plotting\n",
    "        df_plot_list.append(df_plot)\n",
    "\n",
    "    # Plotting\n",
    "    # declare the figure\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Run along the list of dataframes containing plotting data\n",
    "    for i, df_plot in enumerate(df_plot_list):\n",
    "        # Add a line of result per dataframe\n",
    "        fig.add_trace(go.Scatter(x=np.array(df_plot['x']),\n",
    "                                y=np.array(df_plot['y']),\n",
    "                                mode='lines+markers',\n",
    "                                name='Dept. ' + str(departments[i])\n",
    "                                )\n",
    "                    )\n",
    "    # Define the context of the plot\n",
    "    titre = df_dict_labels[label] + \"\\n(per department)\"\n",
    "    fig.update_layout(title=titre,\n",
    "                    xaxis_title=\"Time\",\n",
    "                    yaxis_title=df_dict_labels[label],\n",
    "                    legend=dict(traceorder='reversed'))\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANALYSIS - Data exploration - Time series analysis\n",
    "# ----------------------------------------------------------------------========\n",
    "\n",
    "# I build a function to format x/y values for plotting lines\n",
    "\n",
    "def get_df_dates(dfs, label='timestamp'):\n",
    "    '''\n",
    "    DESCRIPTION\n",
    "        return dataframes with min/max of the column label in abscisse\n",
    "         and index in ordonate. For visualization purpose\n",
    "    INPUT\n",
    "        dfs (list) is a list of dataframes where I will search for  \n",
    "            values in the column named label;\n",
    "        label (string) is the name of the column where I will lokk for \n",
    "              timestamp values; default = 'timestamp'.\n",
    "    OUTPUT\n",
    "        dfs_return (list) is a list of dataframes such that every\n",
    "                   dataframe is defined like:\n",
    "                   {'x' = [values of ‘dates’ from the dataframe] }\n",
    "                   {'y' = [position of the dataframe in the list] }\n",
    "    '''\n",
    "    dfs_return = []\n",
    "\n",
    "    # Run along the list of dataframes\n",
    "    for i, df in enumerate(dfs):\n",
    "        '''\n",
    "        # sort timestamp by ascending order\n",
    "        df.sort_values(by='timestamp', ascending=True, inplace=True)\n",
    "        # get min and max timestamp values given by the dataframe\n",
    "        min_ts, max_ts = df['timestamp'].min(), df['timestamp'].max()\n",
    "        # get date (str) equivalent for these min/max timestamps\n",
    "        min_date = get_df_related_value(df, 'timestamp', 'date', min_ts)\n",
    "        max_date = get_df_related_value(df, 'timestamp', 'date', max_ts)\n",
    "        # build a dataframe with min/max dates and index related to \n",
    "        #  the dataframe.\n",
    "        df_ts = pd.DataFrame(dict(\n",
    "                x = [min_date, max_date],\n",
    "                y = [i+1, i+1]\n",
    "        ))\n",
    "        '''\n",
    "        # get X/Y values\n",
    "        x_values = df['date'].tolist()\n",
    "        y_values = [i+1] * len(x_values)\n",
    "        # format X/Y for ploting\n",
    "        df_ts = pd.DataFrame(dict(\n",
    "                x = x_values,\n",
    "                y = y_values\n",
    "        ))\n",
    "        \n",
    "        # Store the dataframe into the the list of dataframes\n",
    "        dfs_return.append(df_ts)\n",
    "\n",
    "    return dfs_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANALYSIS - Data exploration - Time series analysis\n",
    "# ----------------------------------------------------------------------========\n",
    "\n",
    "# I build a function to format x/y values for plotting lines\n",
    "\n",
    "def plot_df_time_periods(dfs):\n",
    "    '''\n",
    "    DESCRIPTION\n",
    "        Plot a line chart showing the time period of every input \n",
    "         dataframe.\n",
    "    INPUT\n",
    "        dfs (list) is a list of dataframes such that every\n",
    "            dataframe is defined like:\n",
    "            {'x' = [values of ‘dates’ from the dataframe] ] }\n",
    "            {'y' = [position of the dataframe in the list] }\n",
    "    OUTPUT\n",
    "        nil (only display)\n",
    "    '''\n",
    "    # declare the figure\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Run along the list of dataframes containing plotting data\n",
    "    for i, df in enumerate(dfs):\n",
    "        # Add a line of result per dataframe\n",
    "        fig.add_trace(go.Scatter(x=np.array(df['x']),\n",
    "                                 y=np.array(df['y']),\n",
    "                                 mode='lines+markers',\n",
    "                                 name='file' + str(i+1)\n",
    "                                )\n",
    "                    )\n",
    "    # Define the context of the plot\n",
    "    titre = 'Difference of time period covered per data file'\n",
    "    fig.update_layout(title=titre,\n",
    "                    xaxis_title=\"time line\",\n",
    "                    yaxis_title=\"File#\",\n",
    "                    legend=dict(traceorder='reversed'))\n",
    "    fig.update_yaxes(range=[0.5, len(dfs)+0.5])\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANALYSIS - Data exploration & Vizualization - Time series analysis\n",
    "# ----------------------------------------------------------------------========\n",
    "# plot time period for every input dataframe\n",
    "dfs = get_df_dates(df_list)  # Get data for plotting\n",
    "plot_df_time_periods(dfs)  # Plot the time periods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANALYSIS - Data exploration & Vizualization - Time series analysis\n",
    "# ----------------------------------------------------------------------========\n",
    "# According to the times epriod s showed here-above and the cound of\n",
    "#  dates per files, I will keep only data from files #3 and #4 for \n",
    "#  merging and further works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANALYSIS - Data exploration & Vizualization - labels overlapping\n",
    "# ----------------------------------------------------------------------========\n",
    "# before merging dataframes, I'll define how labels will be used merging\n",
    "#  dataframes and if there is no overlapping of labels that could create\n",
    "# some conflicts.\n",
    "\n",
    "df3_labels = df3.columns.values\n",
    "df4_labels = df4.columns.values\n",
    "\n",
    "# I search among labels of df3 which are also present in df4\n",
    "for label in df3_labels:\n",
    "    if label in df4_labels:\n",
    "        print('df3_labels[', label, '] also in df4_labels')\n",
    "\n",
    "# I search among labels of df4 which are also present in df3\n",
    "for label in df4_labels:\n",
    "    if label in df3_labels:\n",
    "        print('df4_labels[', label, '] also in df3_labels')\n",
    "\n",
    "# Conclusion only labels 'dep' and 'date' are common in both files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Data preprocessing - Files data merging\n",
    "# ----------------------------------------------------------------------========\n",
    "\n",
    "# Build a function that provide the list of common values through\n",
    "#  several dataframes for a given column's label.\n",
    "\n",
    "'''Discussion\n",
    "It may take a long time so there is certainly means to re-factorize \n",
    " this part of the code.\n",
    "'''\n",
    "\n",
    "def get_common_values(dfs, label):\n",
    "    '''\n",
    "    DESCRIPTION\n",
    "        get common values on the selectec label through all given \n",
    "         dataframes\n",
    "    INPUT\n",
    "        dfs (list) is the list of all dataframes.\n",
    "        label (string) is the name of the column for which I want\n",
    "         find common values.\n",
    "    OUTPUT\n",
    "        common_values is a numpy array of the common values\n",
    "    '''\n",
    "    common_values, all_values = [], []\n",
    "\n",
    "    # run along every dataframe to find all values through all\n",
    "    #  dataframes.\n",
    "    for df in dfs:\n",
    "        # get an array of values of the selected label\n",
    "        values = np.unique(np.array(df[label]))\n",
    "        # run along these values \n",
    "        for value in values:\n",
    "            # if the value is not in the list of all values, I add it \n",
    "            #  to this list\n",
    "            if value not in all_values:\n",
    "                all_values.append(value)\n",
    "    # all_values contains the list of all values of the column label \n",
    "    #  contained in all dataframes.\n",
    "\n",
    "    # Run along all values to find only common values through all\n",
    "    #  dataframes.\n",
    "    for value in all_values:\n",
    "        cnt = 0  # count the number of occurrence of this value\n",
    "        for df in dfs:\n",
    "            values = np.unique(np.array(df[label]))\n",
    "            if value in values:\n",
    "                cnt += 1\n",
    "        if cnt == len(dfs):\n",
    "            common_values.append(value)\n",
    "    \n",
    "    return np.array(common_values)\n",
    "\n",
    "\n",
    "# Test function get_common_values\n",
    "df_test1 = pd.DataFrame({'date': ['2020-05-12', '2020-06-13', '2021-07-06', '2021-08-01', '2022-01-22', '2022-02-23']})\n",
    "df_test2 = pd.DataFrame({'date': ['2020-05-13', '2020-06-13', '2021-07-06', '2021-08-01', '2022-01-22', '2022-02-23']})\n",
    "df_test3 = pd.DataFrame({'date': ['2020-05-13', '2020-06-13', '2021-07-06', '2021-08-01', '2022-01-22', '2022-02-24']})\n",
    "toto = get_common_values([df_test1, df_test2, df_test3], 'date')\n",
    "print('computed {}\\nexpected {}'.format(toto, np.array(['2020-06-13', '2021-07-06', '2021-08-01', '2022-01-22'])))\n",
    "del df_test1, df_test2, df_test3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Data preprocessing - Files data merging\n",
    "# ----------------------------------------------------------------------========\n",
    "\n",
    "# Merge the dataframes with 'date' and 'dep' as common columns.\n",
    "df = pd.merge(df3, df4, on=['date', 'dep'], how='inner')\n",
    "print(df3.shape, \"+\", df4.shape, \"=\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A step back\n",
    "# ANALYSIS - Data exploration and vizualization - distribution of data\n",
    "# ----------------------------------------------------------------------========\n",
    "# Since I would work on different level of area (department, region,\n",
    "#  France), I would have a view on the distribution of data per \n",
    "#  department and region\n",
    "# Haute-Garonne = 31\n",
    "\n",
    "# Count number of rows (date) per department\n",
    "# create a dictionary of this counting:\n",
    "# key = dept id, value = count of rows per dept.\n",
    "df_sort_dep2_dict = (df.groupby(['dep'])['dep'].count()).to_dict()\n",
    "\n",
    "# push keys and values in list for further plotting\n",
    "dep_ids, dep_data_qty = [], []\n",
    "qty_max = 0\n",
    "for dep_id in df_sort_dep2_dict:\n",
    "    dep_ids.append(dep_id)\n",
    "    qty = df_sort_dep2_dict[dep_id]\n",
    "    dep_data_qty.append(qty)\n",
    "    if qty > qty_max:\n",
    "        qty_max = qty\n",
    "print('Maximum:', qty_max)\n",
    "\n",
    "# plot quantity of data per department\n",
    "titre = \"Quantity of data per French department\"\n",
    "fig = go.Figure(\n",
    "    data=[go.Bar(x=dep_ids, y=dep_data_qty)],\n",
    "    layout=go.Layout(\n",
    "        title=go.layout.Title(text=titre),\n",
    "        xaxis_title=\"dept id\",\n",
    "        yaxis_title=\"Nb of dates with data\"\n",
    "    )\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANALYSIS - Data exploration and vizualization - distribution of data\n",
    "# ----------------------------------------------------------------------========\n",
    "# Count number of rows (date) per region\n",
    "# Occitanie = 76\n",
    "\n",
    "# Count number of rows (date) per region\n",
    "\n",
    "# create a dictionary of this counting:\n",
    "# key = region id, value = count of rows per region.\n",
    "df_sort_reg2_dict = (df.groupby(['reg'])['reg'].count()).to_dict()\n",
    "\n",
    "# push keys and values in list for further plotting\n",
    "reg_ids, reg_data_qty = [], []\n",
    "max_qty = 0\n",
    "for reg_id in df_sort_reg2_dict:\n",
    "    reg_ids.append(reg_id)\n",
    "    qty = df_sort_reg2_dict[reg_id]\n",
    "    reg_data_qty.append(qty)\n",
    "    if qty > qty_max:\n",
    "        qty_max = qty\n",
    "print('Maximum:', qty_max)\n",
    "\n",
    "# plot quantity of data per region\n",
    "fig = go.Figure(\n",
    "    data=[go.Bar(x=reg_ids, y=reg_data_qty)],\n",
    "    layout=go.Layout(\n",
    "        title=go.layout.Title(text=\"Quantity of data per French region\"),\n",
    "        xaxis_title=\"reg id\",\n",
    "        yaxis_title=\"Nb of dates with data\"\n",
    "    )\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Data preprocessing - Files data merging\n",
    "# ----------------------------------------------------------------------========\n",
    "# See above (before checking of the data distribution)\n",
    "# let's have a view on the result of the analysis of the merged data set\n",
    "display_columns_info(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Data preprocessing - Missing values\n",
    "# ----------------------------------------------------------------------========\n",
    "# Remove columns with too many missing values in accordance with\n",
    "#  observations raised during the data exploration and raised here-above\n",
    "\n",
    "# df.drop(columns=remove_list1, inplace=True)  # from df1 (not used)\n",
    "df.drop(columns=remove_list3, inplace=True)  # from df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Data preprocessing - labels renaming\n",
    "# ----------------------------------------------------------------------========\n",
    "# Rename columns with too many missing values in accordance with\n",
    "#  observations raised during the data exploration \n",
    "\n",
    "# df.rename(renaming_4_dict, axis=1, inplace=True)  # from df4\n",
    "# to be done before merging because it's a label to merge with\n",
    "# and before the time series analysis which is based on 'date'.\n",
    "\n",
    "#df.rename(renaming_5_dict, axis=1, inplace=True)  # from df5 (not used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Data preprocessing - Data format\n",
    "# ----------------------------------------------------------------------========\n",
    "\n",
    "# dep has mix format values because of the presence of the 2 departments\n",
    "#  in Corse: 2A and 2B; for ease use of the dep values, I want all these\n",
    "#  values in integer format; so I will convert these both hybrid values\n",
    "#  into intergers\n",
    "\n",
    "# create a function that allows replacing str by int values\n",
    "\n",
    "def replace_str_id(df, label):\n",
    "    '''\n",
    "    DESCRIPTION\n",
    "\n",
    "    INPUT\n",
    "        df is the pandas dataframe\n",
    "        label (string) is the label of the column to process\n",
    "              'dep' or 'region'.\n",
    "    OUTPUT\n",
    "        df is the input pandas dataframe with string values of label\n",
    "        replace by int values.\n",
    "\n",
    "    comment:\n",
    "        think about specific Corse departments 2A and 2B\n",
    "        that I propose to replace by 201 and 202.\n",
    "\n",
    "    '''\n",
    "    dico = {'2A': 201, '2B': 202}\n",
    "\n",
    "    # get unique values of the label\n",
    "    values = np.array(df[label].values)\n",
    "\n",
    "    convert = []\n",
    "    # Run along the values for conversion from str to int\n",
    "    for value in values:\n",
    "        # It try to refers to the dictionary for Corse's deps\n",
    "        try:\n",
    "            # basically, I try to convert str to int\n",
    "            c = int(value)\n",
    "        except:\n",
    "            # when it fails,\n",
    "            if value in dico:\n",
    "                c = dico[value]\n",
    "            else:\n",
    "                # otherwise I apply value zero\n",
    "                c = 0\n",
    "        '''\n",
    "        if (value in dico_keys):\n",
    "            c = dico[value]\n",
    "        else:\n",
    "        '''\n",
    "        convert.append(c)\n",
    "\n",
    "    df[label] = np.array(convert)\n",
    "    df[label] = df[label].astype(int)  # Ensure format for the columns.\n",
    "                                       # Do not put before otherwise,\n",
    "                                       #  it fails to convert 2A and \n",
    "                                       #  2B and display and warning\n",
    "\n",
    "    return df\n",
    "\n",
    "# check the function\n",
    "df_test = pd.DataFrame({'dep': np.array(['01', 21, '2A', '2B', '196'])})\n",
    "result = replace_str_id(df_test, 'dep')\n",
    "solution = [1, 21, 201, 202, 196]\n",
    "print('computed: {}\\nexpected: {}'.format(np.array(result['dep']),\n",
    "                                          solution))\n",
    "\n",
    "# I convert 'dep' and 'reg' to int values\n",
    "df = replace_str_id(df, 'dep')\n",
    "df = replace_str_id(df, 'reg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Data preprocessing - Data format\n",
    "# ----------------------------------------------------------------------========\n",
    "# In addition, I should remove the textual name of the departments to\n",
    "#  keep only values into the dataframe.\n",
    "# Prior removing these names, I will built a dictionary with these names\n",
    "#  and their number to recall these names for further display if needed.\n",
    "\n",
    "# Create a dictionary: key = dept id, value = dept name\n",
    "dep_nums = df['dep'].values\n",
    "dep_names = df['lib_dep'].values\n",
    "dep_num_to_name_dict = dict()\n",
    "for i, num in enumerate (dep_nums):\n",
    "    if num not in dep_num_to_name_dict:\n",
    "        dep_num_to_name_dict[num] = dep_names[i]\n",
    "print('dict of dep:\\n', dep_num_to_name_dict)\n",
    "\n",
    "# Idem with regions\n",
    "reg_nums = df['reg'].values\n",
    "reg_names = df['lib_reg'].values\n",
    "reg_num_to_name_dict = dict()\n",
    "for i, num in enumerate (reg_nums):\n",
    "    if num not in reg_num_to_name_dict:\n",
    "        reg_num_to_name_dict[num] = reg_names[i]\n",
    "print('dict of reg:\\n', reg_num_to_name_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Data preprocessing - Data format\n",
    "# ----------------------------------------------------------------------========\n",
    "# Build Department & Region dictionaries\n",
    "\n",
    "# I build a function dedicated to the identification of a name of\n",
    "#  the department according to its id. \n",
    "\n",
    "def get_dep_name(dep_id):\n",
    "    '''\n",
    "    DESCRIPTION\n",
    "        give the name of a department in accordance with its id\n",
    "    INPUT\n",
    "        dep_id is the id (int) of the department from\n",
    "               which we want the name.\n",
    "    OUTPUT\n",
    "        dep_name is the name (str) of the department related to the\n",
    "                 given id.\n",
    "    '''\n",
    "    try:\n",
    "        name = dep_num_to_name_dict[dep_id]\n",
    "    except:\n",
    "        name = 'unknown'\n",
    "    return name\n",
    "\n",
    "# Check the function with various formats\n",
    "\n",
    "t_int = get_dep_name(45)\n",
    "t_cor = get_dep_name(201)\n",
    "t_unk = get_dep_name(600)\n",
    "print('Loiret: {}'.format(t_int))\n",
    "print('Corse-du-Sud: {}'.format(t_cor))\n",
    "print('unknown: {}'.format(t_unk))\n",
    "\n",
    "# Then I build a function dedicated to the identification of a name of\n",
    "#  the region according to its id. \n",
    "def get_reg_name(reg_id):\n",
    "    '''\n",
    "    DESCRIPTION\n",
    "        give the name of a region in accordance with its id\n",
    "    INPUT\n",
    "        reg_id is the id (str, int or float) of the region from which\n",
    "               we want the name.\n",
    "    OUTPUT\n",
    "        reg_name is the name (str) of the region related to the given\n",
    "                 id.\n",
    "    '''\n",
    "    try:\n",
    "        name = reg_num_to_name_dict[reg_id]\n",
    "    except:\n",
    "        name = 'unknown'\n",
    "    return name\n",
    "\n",
    "# Check the function with various formats\n",
    "t_int = get_reg_name(93)\n",
    "t_unk = get_reg_name(604)\n",
    "solution = \"Provence-Alpes-Côte d'Azur\"\n",
    "print(\"{}: {} - unknown: {}\".format(solution, t_int, t_unk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Data preprocessing - Data format\n",
    "# ----------------------------------------------------------------------========\n",
    "# Then by extension, I build a function to provide the name of\n",
    "#  departments from a list of their ids.\n",
    "\n",
    "def get_dep_names(dep_ids: list):\n",
    "    '''\n",
    "    DESCRIPTION\n",
    "        give a list of department names according to a list of\n",
    "         department ids.\n",
    "    INPUT\n",
    "        dep_ids is the list of department id\n",
    "    OUTPUT\n",
    "        dep_names is the list of department names\n",
    "    '''\n",
    "    dep_names = list()\n",
    "    for dep_id in dep_ids:\n",
    "        dep_names.append(get_dep_name(dep_id))\n",
    "\n",
    "    return dep_names\n",
    "\n",
    "# Check the function\n",
    "list_dep_ids = [45, 21]\n",
    "solution = ['Loiret', \"Côte-d'Or\"]\n",
    "print('expected: {} vs computed: {}'.format(solution,\n",
    "                                        get_dep_names(list_dep_ids)))\n",
    "\n",
    "\n",
    "# In the same way, I build a function to provide the name of region from\n",
    "#  a list of their ids.\n",
    "def get_reg_names(reg_ids: list):\n",
    "    '''\n",
    "    DESCRIPTION\n",
    "        give a list of region names according to a list of region ids\n",
    "    INPUT\n",
    "        reg_ids is the list of region id\n",
    "    OUTPUT\n",
    "        reg_names is the list of region names\n",
    "    '''\n",
    "    reg_names = list()\n",
    "    for reg_id in reg_ids:\n",
    "        reg_names.append(get_reg_name(reg_id))\n",
    "\n",
    "    return reg_names\n",
    "\n",
    "#  Check the function\n",
    "list_reg_ids = [76, 27]\n",
    "solution = ['Occitanie', 'Bourgogne et Franche-Comté']\n",
    "print('expected: {} vs computed: {}'.format(solution,\n",
    "                                        get_reg_names(list_reg_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Data preprocessing - Data format\n",
    "# ----------------------------------------------------------------------========\n",
    "# Finally I can remove labels of department and region since I have\n",
    "#  their dictionaries.\n",
    "size_before = df.shape\n",
    "df.drop(columns=['lib_dep', 'lib_reg'], inplace=True)\n",
    "\n",
    "# check result of the action:\n",
    "title = \"df's size has changed from\"\n",
    "print(\"{} {} to {}:\".format(title, size_before, df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Data preprocessing - Labels description\n",
    "# ----------------------------------------------------------------------========\n",
    "# Create a dictionary with a shot description of every label for further\n",
    "#  use during visualization of results.\n",
    "df_dict_labels = {\n",
    "    'timestamp': 'number of days passed from start of year 0 A.D.',\n",
    "    'dep': 'Dept.',\n",
    "    'reg': 'Region',\n",
    "    'tx_pos': 'Positivity rate',\n",
    "    'tx_incid': 'Incidence rate',\n",
    "    'TO': 'Hospital occupancy rate',\n",
    "    'hosp': 'Hospitalized People',\n",
    "    'rea': 'People in resuscitation/Intensice care',\n",
    "    'rad': 'Cumulative hospitalized people back to home',\n",
    "    'dchosp': 'Death at hospital',\n",
    "    'reg_rea': 'unknown',\n",
    "    'incid_hosp': 'Nes hospitalization in last 24h',\n",
    "    'incid_rea': 'New people in resuscitation/Intensice care in last 24h',\n",
    "    'incid_rad': 'New people hospitalized back to home in last 24h',\n",
    "    'incid_dchosp': 'New death in last 24h',\n",
    "    'reg_incid_rea': 'unknown',\n",
    "    'pos': 'Positive case (J-3)',\n",
    "    'pos_7j': 'Positive case on a week',\n",
    "    'n_dose1': 'Vaccinated with 1 dose',\n",
    "    'n_complet': 'Vaccinated with 2 doses',\n",
    "    'n_rappel': 'Vaccinated with 1 booster dose',\n",
    "    'n_2_rappel': 'Vaccinated with 2 booster doses',\n",
    "    'n_rappel_biv': 'Vaccinated with 1 booster dose (adj. Omicron)',\n",
    "    'n_3_rappel': 'Vaccinated with 3 booster doses',\n",
    "    'n_cum_dose1': 'Cumulative vaccinated with 1 dose',\n",
    "    'n_cum_complet': 'Cumulative vaccinated with 2 doses',\n",
    "    'n_cum_rappel': 'Cumulative vaccinated with 1 booster dose',\n",
    "    'n_cum_2_rappel': 'Cumulative vaccinated with 2 Booster doses',\n",
    "    'n_cum_rappel_biv': 'Cumulative vaccinated with 1 booster dose (adj. Omicron)',\n",
    "    'n_cum_3_rappel': 'Cumulative vaccinated with 3 Booster doses',\n",
    "    'couv_dose1': 'Vaccination coverage with 1 dose',\n",
    "    'couv_complet': 'Vaccination coverage with 2 doses',\n",
    "    'couv_rappel': 'Vaccination coverage with 1 booster dose',\n",
    "    'couv_2_rappel': 'Vaccination coverage with 2 booster doses',\n",
    "    'couv_rappel_biv':'Vaccination coverage with 1 booster dose (adj. Omicron)',\n",
    "    'couv_3_rappel': 'Vaccination coverage with 3 booster doses'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Data preprocessing - Time format\n",
    "# ----------------------------------------------------------------------========\n",
    "# Add timestamp column and remove the column with dates\n",
    "\n",
    "# Create a kind of calendar that provide the number of cumumlated passed\n",
    "#  days at beginning of every month since beginning of the year.\n",
    "\n",
    "def get_cumul_days():\n",
    "    '''\n",
    "    DESCRIPTION\n",
    "        Return a list to ease count, month per month, passed day from\n",
    "         the beginning of the year.\n",
    "    INPUT\n",
    "        nil\n",
    "    OUTPUT\n",
    "        cnt_day_at_start_month is a list that gives the nb of past days\n",
    "         from beginning of the year for every month.\n",
    "    '''\n",
    "    cnt_day_at_start_month = []\n",
    "\n",
    "    day_by_month = [0, 31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]\n",
    "    cnt = 0\n",
    "\n",
    "    for i in day_by_month:\n",
    "        cnt += i \n",
    "        cnt_day_at_start_month.append(cnt)\n",
    "\n",
    "    return cnt_day_at_start_month\n",
    "\n",
    "# Chech the function\n",
    "calendar = get_cumul_days()\n",
    "print('calender:', calendar)\n",
    "\n",
    "\n",
    "# Then I use this calendar to build a function that will provide the\n",
    "#  number of passed days since beginning of the year to beginning of\n",
    "#  the selected month.\n",
    "\n",
    "def cnt_day_beg_month(m, calendar):\n",
    "    '''\n",
    "    DESCRIPTION\n",
    "        get the number of past days from the beginning of year and at \n",
    "         beginning of the selected month.\n",
    "    INPUT\n",
    "        m is the selected month (str of int, int or float)\n",
    "        calendar is a list that gives the nb of past days from\n",
    "                 beginning of the year for every month\n",
    "    OUTPUT\n",
    "        cnt is the count of days (int) from beginning of the year at\n",
    "         start of the selected month.\n",
    "    '''\n",
    "    cnt = calendar[int(m)-1]\n",
    "    return cnt\n",
    "\n",
    "# Check the function\n",
    "# 31 days passed at beginning of february.\n",
    "result = cnt_day_beg_month(2, calendar)\n",
    "print('result: {} vs expected: {}'.format(result, 31))\n",
    "\n",
    "\n",
    "# Finally, I compute a timestamp from the dates as the number of days\n",
    "#  passed  from 0 to the selected day such as for instances:\n",
    "# 2022-06-24 => 2022 * nb_days_passed_to_this_year from year 0\n",
    "#               + nb_passed_days_from_begin_of_the_year_to_begin_of\n",
    "#                 this_month\n",
    "#               + 24 (nb of days passed since beginning of the month)\n",
    "#               = 2022 * 365.24219 + 151 + 24 = 738695\n",
    "# 0000-01-01 => 0 + 0 + 1 = 1\n",
    "\n",
    "\n",
    "def get_timestamp_array(dates_str):\n",
    "    '''\n",
    "    DESCRIPTION\n",
    "        Convert an np.array of dates in string format\n",
    "        to a timestamp in number of days.\n",
    "    INPUT\n",
    "        dates_str is a np.array of dates YYYY-MM-DD in string format\n",
    "    OUTPUT\n",
    "        timestamp is np.array with data converted in number of days(int)\n",
    "    '''\n",
    "    timestamp = []\n",
    "    j = 0\n",
    "    for d in dates_str:\n",
    "        try:\n",
    "            y = float(d[:4])\n",
    "            m = float(d[5:7])\n",
    "            d = float(d[8:10])\n",
    "            # convert the data in number of days\n",
    "            cnt_days_for_months = float(cnt_day_beg_month(m, calendar))\n",
    "            ts = y * 365.24219 + cnt_days_for_months + d\n",
    "        except:\n",
    "            ts = 0.0\n",
    "        ts_r = round(ts, 0)\n",
    "        timestamp.append(int(ts_r))\n",
    "        j += 1\n",
    "    return np.array(timestamp)\n",
    "\n",
    "# Check the function\n",
    "test_dates = np.array(['2022-06-24', '0000-01-01'])\n",
    "timestamp_arr = get_timestamp_array(test_dates)\n",
    "print('expected: {} vs computed {}'.format([738695, 1], timestamp_arr))\n",
    "\n",
    "\n",
    "# Add a timestamp column in df\n",
    "# It will hep for displaying data in time series and find most recent\n",
    "#  values per department.\n",
    "df['timestamp'] = get_timestamp_array(np.array(df['date']))\n",
    "# update the labels dictionary\n",
    "df_dict_labels['timestamp'] = 'Timestamp'\n",
    "# As a reminder, I've decided to keep the column 'date' for avoid \n",
    "#  need to rebuild the date value in string format from the timestamp\n",
    "#  when needed.\n",
    "\n",
    "# remove the column 'date' (str):\n",
    "df_ = df.copy(deep=True)\n",
    "df.drop(columns='date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Data preprocessing - view\n",
    "# ----------------------------------------------------------------------========\n",
    "# Let's have a view on the result of the operations\n",
    "display_columns_info(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Data preprocessing - view\n",
    "# ----------------------------------------------------------------------========\n",
    "# Remove residual missing values\n",
    "\n",
    "size_before = df.shape\n",
    "# I remove all rows containing at least one nan\n",
    "df.dropna(axis='index', how='any', inplace=True)\n",
    "\n",
    "# check result of the action:\n",
    "title = \"df's size has changed from\"\n",
    "print(\"{} {} to {}:\".format(title, size_before, df.shape))\n",
    "\n",
    "# Check result of the action\n",
    "display_columns_info(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Data understanding - Distribution of targets' values\n",
    "# ----------------------------------------------------------------------========\n",
    "# With the purpose of modeling behvaiour of 'hosp' and 'rea' in function\n",
    "#  of the other parameters, I can plot this relation prior modeling it.\n",
    "\n",
    "# For that purpose, I will consider three sets of data:\n",
    "#  - Data for France\n",
    "#  - Data for the Region Occitanie #76\n",
    "#  - Data for the department Haute-Garonne #31\n",
    "\n",
    "# One dataframe for France\n",
    "df_Fr = df.copy(deep=True)\n",
    "# remove departments 'dep', 'reg' and time 'timestamp'\n",
    "df_Fr = df_Fr.drop(columns=['dep', 'reg', 'timestamp'])\n",
    "print('dataframe France:', df_Fr.shape)\n",
    "\n",
    "# One dataframe for region Occintanie\n",
    "df_R76 = df.copy(deep=True)\n",
    "# keep only data for region Occitanie #76\n",
    "df_R76 = df_R76.loc[df_R76['reg'] == 76]\n",
    "# remove departments 'dep', 'reg' and time 'timestamp'\n",
    "df_R76 = df_R76.drop(columns=['dep', 'reg', 'timestamp'])\n",
    "print('dataframe Occitanie:', df_R76.shape)\n",
    "\n",
    "# One dataframe for department Haute-Garonne\n",
    "df_D31 = df.copy(deep=True)\n",
    "# keep only data for department Haute-Garonne 31\n",
    "df_D31 = df_D31.loc[df_D31['dep'] == 31]\n",
    "# remove departments 'dep', 'reg' and time 'timestamp'\n",
    "df_D31 = df_D31.drop(columns=['dep', 'reg', 'timestamp'])\n",
    "print('dataframe haute-Garonne:', df_D31.shape)\n",
    "\n",
    "\n",
    "# Let's have a view on the value distribution of both targets: 'hosp' and 'rea)\n",
    "# source: https://moncoachdata.com/blog/regression-lineaire-sur-un-cas-reel/\n",
    "# Plot of the target label 'hosp'\n",
    "sns.displot(data=df_Fr,x='hosp', bins=30, kde=True).set(title='Values distribution on France')\n",
    "sns.displot(data=df_R76,x='hosp', bins=30, kde=True).set(title=\"Values distribution on Region Occitanie\")\n",
    "sns.displot(data=df_D31,x='hosp', bins=30, kde=True).set(title=\"Values distribution on department Haute-Garonne\")\n",
    "\n",
    "# Plot of the target label 'rea'\n",
    "sns.displot(data=df_Fr,x='rea', bins=30, kde=True).set(title='Values distribution on France')\n",
    "sns.displot(data=df_R76,x='rea', bins=30, kde=True).set(title=\"Values distribution on Region Occitanie\")\n",
    "sns.displot(data=df_D31,x='rea', bins=30, kde=True).set(title=\"Values distribution on department Haute-Garonne\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Data understanding - Correlation with targets\n",
    "# ----------------------------------------------------------------------========\n",
    "# This step consists in plotting targets in function of other labels.\n",
    "\n",
    "# So I start be defining a function to plot these values\n",
    "def plot_x_y(df, x_label_list, y_label, subtitle):\n",
    "    \"\"\"\n",
    "    DESCRIPTION\n",
    "        Plot Y=f(X) for one Y and a list of X\n",
    "    INPUTS\n",
    "        df  is the dataframe to read for plotting\n",
    "             a list of labels in x in relation with\n",
    "             a unique label in y\n",
    "        x_label_list  is a list of labels (string) for\n",
    "                       whom I want to plot values in x.\n",
    "        y_label  is the label (string) for whom I want\n",
    "                  to plot values in y.\n",
    "    OUTPUTS\n",
    "        nil (plot plt)\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(20, 5))\n",
    "\n",
    "    # Plot a graph for every label of the x list\n",
    "    for i, col in enumerate(x_label_list):\n",
    "        plt.subplot(1, len(x_label_list) , i+1)\n",
    "        x = df[col]\n",
    "        y = df[y_label]\n",
    "        plt.scatter(x, y, marker='o')\n",
    "        plt.title(y_label + '=fn(' + col + ') - Area: ' + subtitle)\n",
    "        plt.xlabel(col)\n",
    "        plt.ylabel(y_label)\n",
    "\n",
    "\n",
    "# Get the list of all labels available\n",
    "labels_list = df_Fr.columns.to_list()\n",
    "# df_Fr contains df's labels without 'dep', 'reg' and 'timestamp': ok\n",
    "\n",
    "# Define a function to remove a label from a list of labels\n",
    "def remove_label_from_list(input_list, label_to_remove):\n",
    "    output_list = []\n",
    "    for label in input_list:\n",
    "        if label != label_to_remove:\n",
    "            output_list.append(label)\n",
    "    return output_list\n",
    "\n",
    "# Remove labels of both targets 'hosp' and 'rea' from the list of labels\n",
    "hosp_list = remove_label_from_list(labels_list, 'hosp')\n",
    "liste = remove_label_from_list(hosp_list, 'rea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Data understanding - Correlation between targets\n",
    "# ----------------------------------------------------------------------========\n",
    "# plot 'rea' in function of 'hosp' at level of France\n",
    "plot_x_y(df_Fr, ['hosp'], 'rea', 'France')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Data understanding - Correlation between targets\n",
    "# ----------------------------------------------------------------------========\n",
    "# plot 'rea' in function of 'hosp' at level of the Region\n",
    "plot_x_y(df_R76, ['hosp'], 'rea', 'Region Occitanie (#76)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Data understanding - Correlation between targets\n",
    "# ----------------------------------------------------------------------========\n",
    "# plot 'rea' in function of 'hosp' at level of the department\n",
    "plot_x_y(df_D31, ['hosp'], 'rea', 'Department Haute-Garonne (#31)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Data understanding - Correlation with targets\n",
    "# ----------------------------------------------------------------------========\n",
    "# plot labels for target 'hosp' at level of France\n",
    "start = 0\n",
    "end = start + 6\n",
    "plot_x_y(df_Fr, liste[start:end], 'hosp', 'France')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = end\n",
    "end = start + 6\n",
    "plot_x_y(df_Fr, liste[start:end], 'hosp', 'France')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = end\n",
    "end = start + 6\n",
    "plot_x_y(df_Fr, liste[start:end], 'hosp', 'France')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = end\n",
    "end = start + 6\n",
    "plot_x_y(df_Fr, liste[start:end], 'hosp', 'France')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = end\n",
    "end = start + 7\n",
    "plot_x_y(df_Fr, liste[start:end], 'hosp', 'France')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Data understanding - Correlation with targets\n",
    "# ----------------------------------------------------------------------========\n",
    "# plot labels for target 'hosp' at level of Region Occitanie\n",
    "start = 0\n",
    "end = start + 6\n",
    "plot_x_y(df_R76, liste[start:end], 'hosp', 'Reg.76')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = end\n",
    "end = start + 6\n",
    "plot_x_y(df_R76, liste[start:end], 'hosp', 'Reg.76')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = end\n",
    "end = start + 6\n",
    "plot_x_y(df_R76, liste[start:end], 'hosp', 'Reg.76')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = end\n",
    "end = start + 6\n",
    "plot_x_y(df_R76, liste[start:end], 'hosp', 'Reg.76')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = end\n",
    "end = start + 7\n",
    "plot_x_y(df_R76, liste[start:end], 'hosp', 'Reg.76')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Data understanding - Correlation with targets\n",
    "# ----------------------------------------------------------------------========\n",
    "# plot labels for target 'hosp' at level of Department Haute-Garonne\n",
    "start = 0\n",
    "end = start + 6\n",
    "plot_x_y(df_D31, liste[start:end], 'hosp', 'Dep.31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = end\n",
    "end = start + 6\n",
    "plot_x_y(df_D31, liste[start:end], 'hosp', 'Dep.31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = end\n",
    "end = start + 6\n",
    "plot_x_y(df_D31, liste[start:end], 'hosp', 'Dep.31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = end\n",
    "end = start + 6\n",
    "plot_x_y(df_D31, liste[start:end], 'hosp', 'Dep.31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = end\n",
    "end = start + 7\n",
    "plot_x_y(df_D31, liste[start:end], 'hosp', 'Dep.31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Data understanding - Correlation with targets\n",
    "# ----------------------------------------------------------------------========\n",
    "# plot labels for target 'rea' at level of France\n",
    "\n",
    "# Remove label 'rea' from the list to plot\n",
    "start = 0\n",
    "end = start + 6\n",
    "plot_x_y(df_Fr, liste[start:end], 'rea', 'France')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = end\n",
    "end = start + 6\n",
    "plot_x_y(df_Fr, liste[start:end], 'rea', 'France')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = end\n",
    "end = start + 6\n",
    "plot_x_y(df_Fr, liste[start:end], 'rea', 'France')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = end\n",
    "end = start + 6\n",
    "plot_x_y(df_Fr, liste[start:end], 'rea', 'France')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = end\n",
    "end = start + 7\n",
    "plot_x_y(df_Fr, liste[start:end], 'rea', 'France')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Data understanding - Correlation with targets\n",
    "# ----------------------------------------------------------------------========\n",
    "# plot labels for target 'rea' at level of Occitanie\n",
    "start = 0\n",
    "end = start + 6\n",
    "plot_x_y(df_R76, liste[start:end], 'rea', 'Reg.76')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = end\n",
    "end = start + 6\n",
    "plot_x_y(df_R76, liste[start:end], 'rea', 'Reg.76')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = end\n",
    "end = start + 6\n",
    "plot_x_y(df_R76, liste[start:end], 'rea', 'Reg.76')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = end\n",
    "end = start + 6\n",
    "plot_x_y(df_R76, liste[start:end], 'rea', 'Reg.76')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = end\n",
    "end = start + 7\n",
    "plot_x_y(df_R76, liste[start:end], 'rea', 'Reg.76')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Data understanding - Correlation with targets\n",
    "# ----------------------------------------------------------------------========\n",
    "# plot labels for target 'rea' at level of Haute-Garonne\n",
    "start = 0\n",
    "end = start + 6\n",
    "plot_x_y(df_D31, liste[start:end], 'rea', 'Dep.31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = end\n",
    "end = start + 6\n",
    "plot_x_y(df_D31, liste[start:end], 'rea', 'Dep.31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = end\n",
    "end = start + 6\n",
    "plot_x_y(df_D31, liste[start:end], 'rea', 'Dep.31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = end\n",
    "end = start + 6\n",
    "plot_x_y(df_D31, liste[start:end], 'rea', 'Dep.31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = end\n",
    "end = start + 7\n",
    "plot_x_y(df_D31, liste[start:end], 'rea', 'Dep.31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Data understanding - Assumptions\n",
    "# ----------------------------------------------------------------------========\n",
    "# Need to plot time series\n",
    "# Liste of departments in Region Occitanie\n",
    "d_list = [9, 11, 12, 30, 31, 32, 34, 46, 48, 65, 66, 81, 82]\n",
    "\n",
    "# Group the data set by dep and by timestamp to ease searching results\n",
    "#  by department and by time.\n",
    "if 'dep' in df.columns:\n",
    "    df.groupby(['dep', 'timestamp'])  # If no dummy applied\n",
    "else:\n",
    "    df.groupby(['timestamp'])  # If dummy applied\n",
    "\n",
    "# Plot time series for departments of the Region\n",
    "\"\"\"\n",
    "plot_time_series(df_, label='TO', departments=d_list)\n",
    "plot_time_series(df_, label='rea', departments=d_list)\n",
    "plot_time_series(df_, label='tx_pos', departments=d_list)\n",
    "plot_time_series(df_, label='tx_incid', departments=d_list)\n",
    "plot_time_series(df_, label='rad', departments=d_list)\n",
    "plot_time_series(df_, label='dchosp', departments=d_list)\n",
    "plot_time_series(df_, label='incid_hosp', departments=d_list)\n",
    "plot_time_series(df_, label='incid_rea', departments=d_list)\n",
    "plot_time_series(df_, label='incid_dchosp', departments=d_list)\n",
    "plot_time_series(df_, label='pos', departments=d_list)\n",
    "plot_time_series(df_, label='pos_7j', departments=d_list)\n",
    "plot_time_series(df_, label='n_dose1', departments=d_list)\n",
    "plot_time_series(df_, label='n_2_rappel', departments=d_list)\n",
    "plot_time_series(df_, label='n_rappel_biv', departments=d_list)\n",
    "plot_time_series(df_, label='n_3_rappel', departments=d_list)\n",
    "plot_time_series(df_, label='n_cum_dose1', departments=d_list)\n",
    "plot_time_series(df_, label='n_cum_rappel', departments=d_list)\n",
    "plot_time_series(df_, label='n_cum_2_rappel', departments=d_list)\n",
    "plot_time_series(df_, label='n_cum_rappel_biv', departments=d_list)\n",
    "plot_time_series(df_, label='n_cum_3_rappel', departments=d_list)\n",
    "plot_time_series(df_, label='couv_dose1', departments=d_list)\n",
    "plot_time_series(df_, label='couv_complet', departments=d_list)\n",
    "plot_time_series(df_, label='couv_rappel', departments=d_list)\n",
    "plot_time_series(df_, label='couv_2_rappel', departments=d_list)\n",
    "plot_time_series(df_, label='couv_rappel_biv', departments=d_list)\n",
    "plot_time_series(df_, label='couv_3_rappel', departments=d_list)\n",
    "plot_time_series(df_, label='n_cum_rappel_biv', departments=d_list)\n",
    "\"\"\"\n",
    "# Instruction: activate the line according to your needs\n",
    "plot_time_series(df_, label='n_complet', departments=d_list)\n",
    "plot_time_series(df_, label='n_cum_complet', departments=d_list)\n",
    "plot_time_series(df_, label='n_rappel', departments=d_list)\n",
    "plot_time_series(df_, label='hosp', departments=d_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Main Data extraction\n",
    "# ----------------------------------------------------------------------========\n",
    "# prepare dataframes to be able to train and test on a target without the other target\n",
    "df_Fr_hosp = df_Fr.drop(columns=['rea'])\n",
    "df_Fr_rea = df_Fr.drop(columns=['hosp'])\n",
    "df_R76_hosp = df_R76.drop(columns=['rea'])\n",
    "df_R76_rea = df_R76.drop(columns=['hosp'])\n",
    "df_D31_hosp = df_D31.drop(columns=['rea'])\n",
    "df_D31_rea = df_D31.drop(columns=['hosp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Implementation - modeling preparation\n",
    "# ----------------------------------------------------------------------========\n",
    "# Create a function for spliting the dataset into explanatory and\n",
    "#  response data sets.\n",
    "\n",
    "def get_X_y(df: object, response:str):\n",
    "    '''\n",
    "    DESCRIPTION\n",
    "        Split df into exploratory X data and response y data\n",
    "    INPUT\n",
    "           df : pandas dataframe\n",
    "           response : target variable\n",
    "    OUTPUT\n",
    "           X : A matrix holding all of the variables you want to\n",
    "               consider when predicting the response\n",
    "           y : the corresponding response vector\n",
    "    '''\n",
    "    # output\n",
    "    X, y = None, None\n",
    "\n",
    "    # Get the Response var\n",
    "    if response in df.columns:\n",
    "        # Split into explanatory and response variables (1/2)\n",
    "        #  Get response variable\n",
    "        y = df[response]\n",
    "        df = df.drop(columns=[response])  # Remove pred_name from df\n",
    "    else:\n",
    "        print(\"\\tCAUTION! Unable to find the response in df\")\n",
    "        y = None\n",
    "\n",
    "    # Get the Exploratory vars\n",
    "    # Split into explanatory and response variables (2/2)\n",
    "    #  Get the input variables i.e. at this level just a copy of df\n",
    "    X = df.copy(deep=True)\n",
    "\n",
    "\n",
    "    if X is None:\n",
    "        print('\\tCAUTION! No X found')\n",
    "    if y is None:\n",
    "        print(' - No y found')\n",
    "\n",
    "    del df, response\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Implementation - modeling preparation\n",
    "# ----------------------------------------------------------------------========\n",
    "# Create a function for getting a trained model with possibility to\n",
    "#  select various the model\n",
    "\n",
    "def get_model(model_name, X: object, y: object, testrate=.3,\n",
    "              alpha_value=.1, n_neighbors_value=5):\n",
    "    '''\n",
    "    DESCRIPTION\n",
    "        Returns a linear prediction model according to train data\n",
    "    INPUT\n",
    "           model_name : name of the selected model to use.\n",
    "                        possible choice: 'LinearRegression',\n",
    "                        'KNeighborsClassifier', 'LogisticRegression',\n",
    "                        'Ridge', 'SVC.linear', 'SVC.poly', 'SVC.rbf',\n",
    "                        'DecisionTreeClassifier', 'OneVsRestClassifier',\n",
    "                        'GradientBoostingClassifier',\n",
    "                        'RandomForestClassifier',\n",
    "                        'GradientBoostingRegressor',\n",
    "                        'GradientBoostingClassifier',\n",
    "                        'NeighborsRegressor_uniform',\n",
    "                        'NeighborsRegressor_distance',\n",
    "                        'Lasso'\n",
    "           X          : explanatory variables object\n",
    "           y          : response variable object\n",
    "           testrate   : proportion of the dataset to include in\n",
    "                         the test split,between 0.0 and 1.0;\n",
    "                         default value = 0.3\n",
    "    OUTPUT\n",
    "            model : linear regression model object from sklearn\n",
    "            list of X_train and y_train\n",
    "            list of X_test and y_test\n",
    "    '''\n",
    "    model = None\n",
    "    Xtrain, Xtest, ytrain, ytest = None, None, None, None\n",
    "\n",
    "    # sub-variables\n",
    "    y_pred, split = None, False\n",
    "    \n",
    "    if (X is not None) and (y is not None):\n",
    "        # Split into train and test X/y data set\n",
    "        #  to establish the model and score it\n",
    "        # print(\"- Training\")\n",
    "        Xtrain, Xtest, ytrain, ytest = train_test_split(X, y,\n",
    "                                        test_size=testrate,\n",
    "                                        random_state=42)\n",
    "        if (Xtrain is not None) and (Xtest is not None) and \\\n",
    "           (ytrain is not None) and (ytest is not None):\n",
    "            split = True\n",
    "\n",
    "        # Establish model\n",
    "        # print(\"- Modeling\")\n",
    "        if split:\n",
    "\n",
    "            # Linear model from scikit-learn:\n",
    "            # https://scikit-learn.org/stable/tutorial/\n",
    "            #  statistical_inference/supervised_learning.html\n",
    "\n",
    "            # LINEAR REGRESSION MODELS\n",
    "            # https://scikit-learn.org/stable/modules/linear_model.html#\n",
    "            if model_name == 'LinearRegression':\n",
    "                model = LinearRegression()\n",
    "\n",
    "            # Ridge regression and classification\n",
    "            if model_name == 'Ridge':\n",
    "                model = Ridge(alpha=alpha_value)\n",
    "\n",
    "            if model_name == 'LogisticRegression':\n",
    "                model = LogisticRegression(C=50, max_iter=200)  # C=1e5\n",
    "                # C parameter controls the amount of regularization in\n",
    "                #  the LogisticRegression object:\n",
    "                #  a large value for C results in less regularization.\n",
    "                #  penalty=\"l2\" gives Shrinkage (i.e. non-sparse\n",
    "                #  coefficients), while penalty=\"l1\" gives Sparsity.\n",
    "\n",
    "            if model_name == 'Lasso':\n",
    "                model = linear_model.Lasso(alpha=0.1)\n",
    "\n",
    "\n",
    "            # SUPPORT VECTOR MACHINES\n",
    "            # A priori, not weel adapted for the amount of data of my\n",
    "            #  data set ; could use LinearSVC or SGDClassifier\n",
    "            if model_name == 'SVC.linear':\n",
    "                model = SVC(kernel='linear')\n",
    "\n",
    "            if model_name == 'SVC.poly':\n",
    "                model = SVC(kernel='poly', degree=3)\n",
    "\n",
    "            if model_name == 'SVC.rbf':\n",
    "                model = SVC(kernel='rbf')\n",
    "\n",
    "\n",
    "            # NEAREST NEIGHBORS\n",
    "            #  It would work well on my continuous data\n",
    "            #   but less on 'last-24h' data.\n",
    "            if model_name == 'NeighborsRegressor_uniform':\n",
    "                model = neighbors.KNeighborsRegressor(weights='uniform',\n",
    "                            n_neighbors = n_neighbors_value)\n",
    "\n",
    "            if model_name == 'NeighborsRegressor_distance':\n",
    "                model =neighbors.KNeighborsRegressor(weights='distance')\n",
    "\n",
    "            if model_name == 'KNeighborsClassifier':\n",
    "                model = KNeighborsClassifier()  # n_neighbors=5\n",
    "\n",
    "\n",
    "            # DECISION TREE\n",
    "            # src: https://scikit-learn.org/stable/modules/multiclass.html\n",
    "            if model_name == 'DecisionTreeClassifier':\n",
    "                model = DecisionTreeClassifier()  # random_state=0\n",
    "                # source: https://scikit-learn.org/stable/modules/\n",
    "                #  generated/sklearn.tree.DecisionTreeClassifier.html#\n",
    "                #  sklearn.tree.DecisionTreeClassifier\n",
    "\n",
    "            # ENSEMBLE METHODS\n",
    "            if model_name == 'GradientBoostingRegressor':\n",
    "                model = GradientBoostingRegressor()  # random_state=0            \n",
    "                # source: https://scikit-learn.org/stable/modules/\n",
    "                #  generated/sklearn.ensemble.GradientBoostingRegressor\n",
    "                #  .html\n",
    "\n",
    "            if model_name == 'GradientBoostingClassifier':\n",
    "                model = GradientBoostingClassifier()\n",
    "                # n_estimators=100, learning_rate=1.0, max_depth=1,\n",
    "                #  random_state=0\n",
    "\n",
    "            if model_name == 'RandomForestClassifier':\n",
    "                model = RandomForestClassifier()\n",
    "                # source: https://scikit-learn.org/stable/modules/\n",
    "                #  generated/sklearn.ensemble.RandomForestClassifier\n",
    "                #  .html#sklearn.ensemble.RandomForestClassifier\n",
    " \n",
    " \n",
    "            # fit the model\n",
    "            model.fit(Xtrain, ytrain)\n",
    "\n",
    "            # Test the model on test data\n",
    "            y_pred = model.predict(Xtest)\n",
    "\n",
    "        else:\n",
    "            y_pred = None\n",
    "            print(\"\\tCAUTION! No Model defined\")\n",
    " \n",
    "    return model, [Xtrain, ytrain], [Xtest, ytest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Implementation - modeling preparation\n",
    "# ----------------------------------------------------------------------========\n",
    "# Create a function for evualuating performance of the model\n",
    "\n",
    "def get_model_performance(model, Xy_train, Xy_test, Xy):\n",
    "    '''\n",
    "    DESCRIPTION\n",
    "        Evaluate the model by computing its R2 score.\n",
    "    INPUT\n",
    "        model is the model to evaluate\n",
    "        Xy_train is a list of train data: [X_train, y_train]\n",
    "        Xy_test is a list of test data: [X_test, y_test]\n",
    "        Xy is a list of with all data: [X, y]\n",
    "    OUTPUT\n",
    "        dictionary of scores with values\n",
    "        # score (float) in the measure of the model's performance\n",
    "    '''\n",
    "    \n",
    "    # Get data sets\n",
    "    X_train, y_train = Xy_train\n",
    "    X_test, y_test = Xy_test\n",
    "    X_true, y_true = Xy\n",
    "\n",
    "    # Evaluate this model by gettings metrics with a model by\n",
    "    #  regression: Get the model's score\n",
    "\n",
    "    # Accuracy_score (https://scikit-learn.org/stable/modules/\n",
    "    # generated/sklearn.metrics.accuracy_score.html)\n",
    "    # Confusion matrix (https://scikit-learn.org/stable/modules/\n",
    "    # generated/sklearn.metrics.confusion_matrix.html)\n",
    "    #  not appropriate for my purpose\n",
    "    # Common pitfalls (https://scikit-learn.org/stable/common_\n",
    "    #  pitfalls.html): mean_sqaured_error and r2_score\n",
    "\n",
    "    # According to https://stackoverflow.com/questions/37367405/\n",
    "    #  python-scikit-learn-cant-handle-mix-of-multiclass-and-continuous\n",
    "    # ... Accuracy score is only for classification problems\n",
    "    # acc_score_train = accuracy_score(y_train, model.predict(X_train))\n",
    "    # acc_score_test = accuracy_score(y_test, model.predict(X_test))\n",
    "    # if debug: print(\"    - acc_score_train:\", acc_score_train)\n",
    "    # if debug: print(\"    - acc_score_test:\", acc_score_test)\n",
    "\n",
    "    # always according to https://stackoverflow.com/questions/37367405/\n",
    "    #  python-scikit-learn-cant-handle-mix-of-multiclass-and-continuous\n",
    "    # For regression problems, use: R2 Score, MSE (Mean Squared Error),\n",
    "    # RMSE (Root Mean Squared Error).\n",
    "    \n",
    "\n",
    "\n",
    "    # srce: https://scikit-learn.org/0.15/modules/model_evaluation.html\n",
    "    # and https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "\n",
    "\n",
    "    # Regression scoring\n",
    "    try:\n",
    "        r2_score_value = r2_score(y_true, model.predict(X_true))\n",
    "    except:\n",
    "        r2_score_value = None\n",
    "    try:\n",
    "        explained_variance_score = explained_variance_score(y_true, model.predict(X_true))\n",
    "    except:\n",
    "        explained_variance_score = None\n",
    "\n",
    "\n",
    "    # Classification metrics: For multilabel case scoring\n",
    "    try:\n",
    "        accuracy_score_value = accuracy_score(y_true,\n",
    "                                              model.predict(X_true))\n",
    "    except:\n",
    "        accuracy_score_value = None\n",
    "    try:\n",
    "        precision_score_value = precision_score(y_true,\n",
    "                                                model.predict(X_true),\n",
    "                                                average='micro') \n",
    "    except:\n",
    "        precision_score_value = None\n",
    "    try:\n",
    "        top_k_value = top_k_accuracy_score(y_true, model.predict(X_true),\n",
    "                                           k=2)\n",
    "    except:\n",
    "        top_k_value = None\n",
    "    try:\n",
    "        balanced_value = balanced_accuracy_score(y_true,\n",
    "                                                 model.predict(X_true))\n",
    "    except:\n",
    "        balanced_value = None\n",
    "    try:\n",
    "        # source: https://scikit-learn.org/0.15/modules/generated/sklearn\n",
    "        #  .metrics.f1_score.html#sklearn.metrics.f1_score\n",
    "        f1_score_value = f1_score(y_true, model.predict(X_true),\n",
    "                                  average='micro')\n",
    "    except:\n",
    "        f1_score_value = None\n",
    "\n",
    "    try:\n",
    "        recall_score_value = recall_score(y_true, model.predict(X_true),\n",
    "                                          average='micro') \n",
    "    except:\n",
    "        recall_score_value = None\n",
    "    try:\n",
    "        fscore_value = precision_recall_fscore_support(y_true,\n",
    "                                                model.predict(X_true),\n",
    "                                                average='micro')\n",
    "        # srce: https://scikit-learn.org/0.15/modules/generated/sklearn\n",
    "        # .metrics.precision_recall_fscore_support.html#sklearn.metrics\n",
    "        # .precision_recall_fscore_support\n",
    "    except:\n",
    "        fscore_value = None        \n",
    "\n",
    "    # try:\n",
    "    #   jaccard = jaccard_similarity_score(y_true, model.predict(X_true))\n",
    "    # except:\n",
    "    #   jaccard = None\n",
    "\n",
    "    # source: https://scikit-learn.org/stable/modules/generated/sklearn\n",
    "    # .ensemble.GradientBoostingRegressor.html#sklearn.ensemble\n",
    "    # .GradientBoostingRegressor.score\n",
    "    # source: https://www.kaggle.com/discussions/getting-started/27261\n",
    "    try:\n",
    "        score_value = model.score(X_test, y_test)\n",
    "    except:\n",
    "        score_value = None\n",
    "\n",
    "    # Cross-validation\n",
    "    # source: https://scikit-learn.org/stable/modules/cross_validation.html\n",
    "    try:\n",
    "        cross_val = cross_val_score(model, X_true, y_true)\n",
    "        cross_val_mean = cross_val.mean()\n",
    "        cross_val_stddev = cross_val.std()\n",
    "    except:\n",
    "        cross_val_mean = None\n",
    "        cross_val_stddev = None\n",
    "\n",
    "    # 'jaccard': Not available\n",
    "    # 'cross_val_stddev', 'cross_val_mean', 'recall_score'\n",
    "    #  ... generates issues due to too low number of iterations.\n",
    "    return {'r2_score': r2_score_value,\n",
    "    'explained_variance_score': explained_variance_score,\n",
    "     'accuracy_score': accuracy_score_value,\n",
    "     'top_k': top_k_value,\n",
    "     'balanced': balanced_value,\n",
    "     'fscore': fscore_value,\n",
    "     'f1_score': f1_score_value,\n",
    "     'score': score_value,\n",
    "     'precision_score': precision_score_value}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Implementation - modeling preparation\n",
    "# ----------------------------------------------------------------------========\n",
    "# Create a function for indicating the weight of every parameters\n",
    "\n",
    "def coef_weights(model, X) -> object:\n",
    "    '''\n",
    "    DESCRIPTION\n",
    "       Returns a dataframe with coefficients of the model\n",
    "        (real and absolute values) sorted in the descending order\n",
    "        of the absolute values\n",
    "    INPUT       \n",
    "       model is the model for which we are looking coefficients\n",
    "       X is the exploratory set of data\n",
    "    OUTPUT\n",
    "      coefs_df : model's coefficients that can be used to understand\n",
    "                 the most influential coefficients in a linear model\n",
    "                 by providing the coefficient estimates along with the\n",
    "                 name of the variable attached to the coefficient.\n",
    "    '''\n",
    "    coefs_df = pd.DataFrame()\n",
    "    # Get name of every column in front  of its coefficients\n",
    "    coefs_df['est_int'] = X.columns\n",
    "    # get coefficients of the linear model\n",
    "    coefs_df['coefs'] = model.coef_\n",
    "    # get absolute value of these coefficients\n",
    "    coefs_df['abs_coefs'] = np.abs(model.coef_)\n",
    "    # Sort coefficient by descending order\n",
    "    coefs_df = coefs_df.sort_values('abs_coefs', ascending=False)\n",
    "\n",
    "    return coefs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Implementation - modeling preparation\n",
    "# ----------------------------------------------------------------------========\n",
    "# Create a function that allows launching the modeling\n",
    "\n",
    "def process_model(df, response, model_name, drop_list=[], display=True,\n",
    "                  alpha=.1, n_neighbors=5, scoring_display=[]):\n",
    "    '''\n",
    "    DESCRIPTION\n",
    "        Define, evaluate and discuss a model\n",
    "    INPUT\n",
    "        df is the pandas dataframe with data to build and evaluate the \n",
    "           model;\n",
    "        response (string) is the category / label of the column defined\n",
    "                 as response/target for the model to define;\n",
    "        model_name  is name of the selected model to use.\n",
    "                     possible choice: 'LinearRegression',\n",
    "                     'KNeighborsClassifier', 'LogisticRegression',\n",
    "                     'Ridge', 'SVC.linear', 'SVC.poly', 'SVC.rbf',\n",
    "                     'DecisionTreeClassifier', 'OneVsRestClassifier',\n",
    "                     'GradientBoostingClassifier',\n",
    "                     'RandomForestClassifier',\n",
    "                     'GradientBoostingRegressor',\n",
    "                     'GradientBoostingClassifier',\n",
    "                     'NeighborsRegressor_uniform',\n",
    "                     'NeighborsRegressor_distance',\n",
    "                     'Lasso'\n",
    "        drop_list (list) is a list of categories / labels of the columns\n",
    "                  that can be removed from the dataframe before \n",
    "                  defining and evaluating the model. It does not modify\n",
    "                  input dataframe. Default = nil (empty list)\n",
    "        display  is .................\n",
    "        alpha  is .................\n",
    "        n_neighbors  is ................\n",
    "        scoring_display  is a list of the scores to display;\n",
    "                         if [] i.e. default, display all scores.\n",
    "    OUTPUT\n",
    "        model is the trained model define to predict the response\n",
    "              according to the other labels of the dataframe.\n",
    "        scores is a dictionaru of metrics to measure the performance of\n",
    "               the model.coef_, closer to 1, better.\n",
    "        coefs is the list of labels of the dataframe used to establish\n",
    "              the model for which a weight (contribution to the model)\n",
    "              is computed (signed and absolute values).\n",
    "    '''\n",
    "    model, scores, coefs = None, None, None\n",
    "\n",
    "    df_mdl = df.copy(deep=True)\n",
    "    if display:\n",
    "        print('Modeling...')\n",
    "    # Remove this list of labels\n",
    "    if display:\n",
    "        print('- drop')\n",
    "    if len(drop_list) > 0:\n",
    "        df_mdl.drop(columns=drop_list, inplace=True)\n",
    "\n",
    "    # Split into Response y / Exploratory variables X\n",
    "    if display:\n",
    "        print(\"- Split into X/y\")\n",
    "    X, y = get_X_y(df_mdl, response)\n",
    "\n",
    "    # modeling\n",
    "    if display:\n",
    "        print(\"- Get model\")\n",
    "    model, Xy_train, Xy_test = get_model(model_name, X, y,\n",
    "                                alpha_value=alpha,\n",
    "                                n_neighbors_value=n_neighbors)\n",
    "\n",
    "    # Check performance\n",
    "    if display:\n",
    "        print(\"- Performance\")\n",
    "    scores = get_model_performance(model, Xy_train, Xy_test, [X, y])\n",
    "    for score in scores:\n",
    "        if (scoring_display == []) or (score in scoring_display):\n",
    "            print(\"\\tscore:\", score, scores[score])\n",
    "        \n",
    "    # Coefficients of weight\n",
    "    if display:\n",
    "        print(\"- Model's coefficients\")\n",
    "        coefs = coef_weights(model, X)\n",
    "        pd.set_option(\"display.max_rows\", None,\n",
    "                      \"display.max_columns\", None)    \n",
    "        print(coefs)\n",
    "\n",
    "    return model, scores, coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Implementation - model selection\n",
    "# ----------------------------------------------------------------------========\n",
    "\n",
    "# Create a function that allows applying a list of models on a given \n",
    "#  dataframe to a given target label of the dataframe.\n",
    "def apply_models(models_list, dff, response, alpha_value=0.1,\n",
    "                 n_neighbors_value=5, scoring_sts=[]):\n",
    "    \"\"\"\n",
    "    DESCRIPTION\n",
    "        Apply a list of models on a given dataframe to a given target\n",
    "         label of the dataframe.\n",
    "    INPUT\n",
    "        models_list  is a list of models' names (string) as defined in\n",
    "                      the function 'get_model'.\n",
    "        dff  is the dataframe to work on for training and assessing\n",
    "              a model.\n",
    "        response  is the target label (string) of the modeling.\n",
    "        alpha_value  is ..............\n",
    "        n_neighbors_value  is ..............\n",
    "        scoring_sts  is .................\n",
    "    OUTPUT\n",
    "        none : display of scores for every tested model\n",
    "    \"\"\"\n",
    "    for model_name in models_list:\n",
    "        print('\\nModel:', model_name)\n",
    "        model, score, coefs = process_model(dff, response, model_name,\n",
    "                                display=False,\n",
    "                                alpha=alpha_value,\n",
    "                                n_neighbors = n_neighbors_value,\n",
    "                                scoring_display = scoring_sts)\n",
    "\n",
    "\n",
    "# Define a list of models to test\n",
    "models_list = ['LinearRegression', 'Ridge', \n",
    "               'NeighborsRegressor_distance']\n",
    "# very long: 'SVC.linear', OneVsRestClassifier even on short data set\n",
    "# Negative R2 score: 'GradientBoostingClassifier', 'SVC.poly', 'SVC.rbf'\n",
    "# Do not converge: 'LogisticRegression'\n",
    "# Generate warning: 'KNeighborsClassifier', 'GradientBoostingRegressor',\n",
    "#                   'DecisionTreeClassifier', 'GradientBoostingClassifier',\n",
    "#                   'RandomForestClassifier',\n",
    "# need to increase the number of iterations: 'NeighborsRegressor_uniform',\n",
    "#                                            'Lasso'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Implementation - model selection\n",
    "# ----------------------------------------------------------------------========\n",
    "apply_models(models_list, df_D31_hosp, 'hosp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Implementation - model selection\n",
    "# ----------------------------------------------------------------------========\n",
    "apply_models(models_list, df_R76_hosp, 'hosp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Implementation - model selection\n",
    "# ----------------------------------------------------------------------========\n",
    "# apply_models(models_list, df_Fr_hosp, 'hosp')\n",
    "# deactivated because too long (> 10min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Implementation - model selection\n",
    "# ----------------------------------------------------------------------========\n",
    "apply_models(models_list, df_D31_rea, 'rea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Implementation - model selection\n",
    "# ----------------------------------------------------------------------========\n",
    "apply_models(models_list, df_R76_rea, 'rea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Implementation - model selection\n",
    "# ----------------------------------------------------------------------========\n",
    "# apply_models(models_list, df_Fr_rea, 'rea')\n",
    "# deactivated because too long (> 10min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Implementation - Refinement\n",
    "# ----------------------------------------------------------------------========\n",
    "# remove last-24h data\n",
    "# df_D31_hosp.columns\n",
    "# result = ['tx_pos', 'tx_incid', 'TO', 'hosp', 'rad', 'dchosp', 'reg_rea',\n",
    "#       'incid_hosp', 'incid_rea', 'incid_rad', 'incid_dchosp', 'reg_incid_rea',\n",
    "#       'pos', 'pos_7j', 'n_dose1', 'n_complet', 'n_rappel', 'n_2_rappel',\n",
    "#       'n_rappel_biv', 'n_3_rappel', 'n_cum_dose1', 'n_cum_complet',\n",
    "#       'n_cum_rappel', 'n_cum_2_rappel', 'n_cum_rappel_biv', 'n_cum_3_rappel',\n",
    "#       'couv_dose1', 'couv_complet', 'couv_rappel', 'couv_2_rappel',\n",
    "#       'couv_rappel_biv', 'couv_3_rappel']\n",
    "new_drop_list = ['tx_incid', 'incid_hosp', 'incid_rea', 'incid_rad',\n",
    "                 'incid_dchosp', 'reg_incid_rea']\n",
    "\n",
    "# remove these parameters from the dataframes (work on a copy)\n",
    "df_D31_hosp_red = df_D31_hosp.copy(deep=True)\n",
    "df_R76_hosp_red = df_R76_hosp.copy(deep=True)\n",
    "df_Fr_hosp_red = df_Fr_hosp.copy(deep=True)\n",
    "df_D31_hosp_red = df_D31_hosp_red.drop(columns=new_drop_list)\n",
    "df_R76_hosp_red = df_R76_hosp_red.drop(columns=new_drop_list)\n",
    "df_Fr_hosp_red = df_Fr_hosp_red.drop(columns=new_drop_list)\n",
    "\n",
    "# check of hosp predictions\n",
    "models_list = ['NeighborsRegressor_distance']\n",
    "target = 'hosp'\n",
    "print('DEPARTMENT:')\n",
    "apply_models(models_list, df_D31_hosp_red, target)\n",
    "print('REGION:')\n",
    "apply_models(models_list, df_R76_hosp_red, target)\n",
    "#print('FRANCE:')  # deactivated because too long (> 10min)\n",
    "#apply_models(models_list, df_Fr_hosp_red, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check of hosp predictions\n",
    "models_list = ['NeighborsRegressor_distance']\n",
    "target = 'hosp'\n",
    "n_neighbors = 2\n",
    "print('DEPARTMENT:')\n",
    "apply_models(models_list, df_D31_hosp_red, target, n_neighbors_value=n_neighbors)\n",
    "print('REGION:')\n",
    "apply_models(models_list, df_R76_hosp_red, target, n_neighbors_value=n_neighbors)\n",
    "#print('FRANCE:')  # deactivated because too long (> 10min)\n",
    "#apply_models(models_list, df_Fr_hosp_red, target, n_neighbors_value=n_neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check of hosp predictions\n",
    "models_list = ['NeighborsRegressor_distance']\n",
    "target = 'hosp'\n",
    "n_neighbors = 15\n",
    "print('DEPARTMENT:')\n",
    "apply_models(models_list, df_D31_hosp_red, target, n_neighbors_value=n_neighbors)\n",
    "print('REGION:')\n",
    "apply_models(models_list, df_R76_hosp_red, target, n_neighbors_value=n_neighbors)\n",
    "#print('FRANCE:')  # deactivated because too long (> 10min)\n",
    "#apply_models(models_list, df_Fr_hosp_red, target, n_neighbors_value=n_neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Implementation - Refinement\n",
    "# ----------------------------------------------------------------------========\n",
    "# Test change of alpha on Ridge modeling method: from 0.1 (default)\n",
    "#  to 0.5\n",
    "alpha = 0.5\n",
    "\n",
    "# check of hosp predictions\n",
    "models_list = ['Ridge']\n",
    "target = 'hosp'\n",
    "print('DEPARTMENT:')\n",
    "apply_models(models_list, df_D31_hosp, target, alpha_value=alpha)\n",
    "print('REGION:')\n",
    "apply_models(models_list, df_R76_hosp, target, alpha_value=alpha)\n",
    "print('FRANCE:')\n",
    "apply_models(models_list, df_Fr_hosp, target, alpha_value=alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# METHODOLOGY - Implementation - Refinement\n",
    "# ----------------------------------------------------------------------========\n",
    "# Remove the last-24h data from the data sets\n",
    "new_drop_list = ['tx_incid', 'incid_hosp', 'incid_rea', 'incid_rad',\n",
    "                 'incid_dchosp', 'reg_incid_rea']\n",
    "df2 = df.drop(columns=new_drop_list)\n",
    "df_D31_hosp2 = df_D31_hosp.drop(columns=new_drop_list)\n",
    "df_R76_hosp2 = df_R76_hosp.drop(columns=new_drop_list)\n",
    "df_Fr_hosp2 = df_Fr_hosp.drop(columns=new_drop_list)\n",
    "df_D31_rea2 = df_D31_rea.drop(columns=new_drop_list)\n",
    "df_R76_rea2 = df_R76_rea.drop(columns=new_drop_list)\n",
    "df_Fr_rea2 = df_Fr_rea.drop(columns=new_drop_list)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applying_model(df, model_name=None, response='', testrate=.3):\n",
    "\n",
    "    df_mdl = df.copy(deep=True)\n",
    "\n",
    "    # Define data\n",
    "    X, y = get_X_y(df_mdl, response)\n",
    "\n",
    "    # split data \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                    test_size=testrate,\n",
    "                                    random_state=42)\n",
    "    # Modeling\n",
    "    model = None\n",
    "    if model_name == 'LinearRegression':\n",
    "        model = LinearRegression()\n",
    "    if model_name == 'Ridge':\n",
    "        model = Ridge()\n",
    "    if model_name == 'NeighborsRegressor_distance':\n",
    "        model =neighbors.KNeighborsRegressor(weights='distance')\n",
    "\n",
    "    # fit and apply\n",
    "    if model is not None:\n",
    "        model.fit(X_train, y_train)  # fit the model\n",
    "        y_pred = model.predict(X_test)  # Test the model on test data\n",
    "\n",
    "    # Scoring\n",
    "    try:\n",
    "        r2_score_value = r2_score(y, model.predict(X))\n",
    "    except:\n",
    "        r2_score_value = None\n",
    "    try:\n",
    "        score_value = model.score(X_test, y_test)\n",
    "    except:\n",
    "        score_value = None\n",
    "\n",
    "    return {'r2_score': r2_score_value, 'score': score_value}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Data understanding - Refinement\n",
    "# ----------------------------------------------------------------------========\n",
    "# I would try to reduce the number of parameters by identifying once\n",
    "#  that provide significant result and other that do not.\n",
    "\n",
    "def get_overall_scores(df, target):\n",
    "    \"\"\"\n",
    "    DESCRIPTION\n",
    "        get score of selected model for every parameter; store result\n",
    "         into a dictionary. \n",
    "    INPUT\n",
    "        dfo  is the dataframe\n",
    "        target  is the name of the parameter used as answer (str)\n",
    "    OUTPUT\n",
    "        overall_scores  is a dictionary of model method, providing\n",
    "                        for every method a dictionary of input\n",
    "                        parameters; gives scores for all methods and\n",
    "                        all param:\n",
    "                   {methode1: {p1: {'r2_score': value, 'score': value},\n",
    "                               p2: {}, ...},\n",
    "                    methode2: {...} \n",
    "                   }\n",
    "    \"\"\"\n",
    "    overall_scores = dict()\n",
    "\n",
    "    models_list = ['LinearRegression', 'Ridge', \n",
    "                'NeighborsRegressor_distance']\n",
    "\n",
    "    # get the list of input parameters:\n",
    "    dfo = df.copy(deep=True)\n",
    "    ip_list = dfo.drop(columns=[target]).columns\n",
    "\n",
    "    # for every, modeling method, get scores while using every input \n",
    "    # parameter:\n",
    "    for model in models_list:\n",
    "        overall_scores[model] = dict()    \n",
    "        for ip in ip_list:\n",
    "            df_short =dfo[[target, ip]]\n",
    "            # print('\\n>> Model', model, 'param:', ip)\n",
    "            scores = applying_model(df_short, model_name=model, response=target)\n",
    "            overall_scores[model][ip] = scores\n",
    "\n",
    "    del dfo, target, ip_list, models_list\n",
    "    return overall_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Data understanding - Refinement\n",
    "# ----------------------------------------------------------------------========\n",
    "# In first approach, to quickly get result, focus on the department.\n",
    "overall_scores_hosp_D31 = get_overall_scores(df_D31_hosp, 'hosp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Data understanding - Refinement\n",
    "# ----------------------------------------------------------------------========\n",
    "# Then, I will sort score related to all parameters for every method,\n",
    "# in order to display onces bringing highest scores to lowest.\n",
    "\n",
    "def display_overall_scores(overall_scores, target, score_name):\n",
    "    \"\"\"\n",
    "    DESCRIPTION\n",
    "        Display a plot of score per input parameter and per model.\n",
    "    INPUT\n",
    "        overall_scores  is a dictionary of model method, providing\n",
    "                        for every method a dictionary of input\n",
    "                        parameters; gives scores for all methods and\n",
    "                        all param:\n",
    "                   {methode1: {p1: {'r2_score': value, 'score': value},\n",
    "                               p2: {}, ...},\n",
    "                    methode2: {...} \n",
    "                   }\n",
    "        target  is the name of the parameter selected as answer.\n",
    "        score_name  is the name of the selected type of score.\n",
    "                    choose among variable 'scoring_list'\n",
    "    OUTPUT\n",
    "        none (display)\n",
    "    \"\"\"\n",
    "\n",
    "    models_list = ['LinearRegression', 'Ridge', \n",
    "                   'NeighborsRegressor_distance']\n",
    "\n",
    "    dfp = pd.DataFrame([])\n",
    "    params, scores, models = [], [], []\n",
    "    for i, model in enumerate (models_list):\n",
    "        for param in overall_scores[model]:\n",
    "            params.append(param)\n",
    "            scores.append(overall_scores[model][param][score_name])\n",
    "            models.append(model)\n",
    "\n",
    "    dfp['parameters'] = params\n",
    "    dfp['scores'] = scores\n",
    "    dfp['model'] = models\n",
    "    \n",
    "    fig = px.bar(dfp, x=\"parameters\", y=\"scores\",\n",
    "                color=\"model\",\n",
    "                title=\"Scores with three modeling methods (default settings) for response '\" + target + \"'\",\n",
    "                barmode = 'group')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Data understanding - Refinement\n",
    "# ----------------------------------------------------------------------========\n",
    "# display the result of 'hosp' and at level of department\n",
    "display_overall_scores(overall_scores_hosp_D31, 'hosp', 'score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Data understanding - Refinement\n",
    "# ----------------------------------------------------------------------========\n",
    "# This figure show that some input parameters has a significant impact\n",
    "#  on the scores whatever the modeling method, and some others depend on\n",
    "#  the modeling method.\n",
    "# Such that I assume I can remove somme non significant parameters,\n",
    "#  i.e parameters that give a relative low positive score (not really\n",
    "#  visible on the plot) or a negative score:\n",
    "LinearRegression_keepinglist_hosp = ['tx_pos', 'tx_incid', 'TO',\n",
    " 'reg_rea', 'incid_hosp', 'incid_rea', 'incid_rad', 'incid_dchosp',\n",
    " 'reg_incid_rea', 'pos', 'pos_7j', 'n_dose1', 'n_complet',\n",
    " 'n_cum_rappel', 'couv_rappel']\n",
    "LinearRidge_keepinglist_hosp = LinearRegression_keepinglist_hosp\n",
    "Neighbors_Regressor_keepinglist_hosp = ['tx_pos', 'tx_incid', 'rad',\n",
    " 'dchosp', 'incid_hosp', 'incid_rad', 'reg_incid_rea', 'pos', 'pos_7j',\n",
    " 'n_cum_dose1', 'n_cum_complet', 'n_cum_rappel', 'n_cum_2_rappel',\n",
    " 'n_cum_3_rappel', 'couv_dose1', 'couv_complet', 'couv_rappel',\n",
    " 'couv_2_rappel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Data understanding - Refinement\n",
    "# ----------------------------------------------------------------------========\n",
    "# same work for the second target with a focus on the department.\n",
    "target = 'rea'\n",
    "overall_scores_rea_D31 = get_overall_scores(df_D31_rea, target)\n",
    "display_overall_scores(overall_scores_rea_D31, target, 'score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # METHODOLOGY - Data understanding - Refinement\n",
    "# ----------------------------------------------------------------------========\n",
    "# This figure show that some input parameters has a significant impact\n",
    "#  on the scores whatever the modeling method, and some others depend on\n",
    "#  the modeling method.\n",
    "# Such that I assume I can remove somme non significant parameters:\n",
    "LinearRegression_keepinglist_rea = ['tx_incid', 'TO', 'rad', 'dchosp',\n",
    " 'reg_rea', 'incid_hosp', 'incid_rea', 'incid_rad', 'incid_dchosp',\n",
    " 'reg_incid_rea', 'pos', 'pos_7j', 'n_rappel', 'n_2_rappel',\n",
    " 'n_cum_dose1', 'n_cum_complet', 'n_cum_rappel', 'n_cum_2_rappel',\n",
    " 'n_cum_3_rappel', 'couv_dose1', 'couv_complet', 'couv_rappel',\n",
    " 'couv_2_rappel', 'couv_rappel_biv', 'couv_3_rappel']\n",
    "LinearRidge_keepinglist_rea = LinearRegression_keepinglist_rea\n",
    "Neighbors_Regressor_keepinglist_rea = ['tx_pos', 'tx_incid', 'TO',\n",
    " 'rad', 'dchosp', 'reg_rea', 'incid_hosp', 'reg_incid_rea', 'pos_7j',\n",
    "  'n_dose1', 'n_complet', 'n_rappel', 'n_cum_dose1', 'n_cum_complet',\n",
    "  'n_cum_rappel', 'n_cum_2_rappel', 'n_cum_3_rappel', 'couv_dose1',\n",
    "  'couv_complet', 'couv_rappel', 'couv_2_rappel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Data understanding - Refinement\n",
    "# ----------------------------------------------------------------------========\n",
    "# Create new data sets only with parameters to keep as identified\n",
    "#  here-above for the three modeling methods. (always at department\n",
    "#  level).\n",
    "def compare_df_columns(df1, df2, title=''):\n",
    "    \"\"\"\n",
    "    DESCRIPTION\n",
    "        Display difference of columns' name between two dataframes.\n",
    "    INPUT\n",
    "        df1  is the first dataframe to compare\n",
    "        df2  is the second dataframe to compare\n",
    "    OUTPUT\n",
    "        none (only display)\n",
    "    \"\"\"\n",
    "    l1 = df1.columns\n",
    "    l2 = df2.columns\n",
    "\n",
    "    # Work as if df2 as lower columns than df1.\n",
    "    # Indicate how many stay and how many leave\n",
    "    nb_stay, nb_leave = 0, 0\n",
    "    # Compute nb kept\n",
    "    for n2 in l2:\n",
    "        for n1 in l1:   \n",
    "            if n2 == n1:\n",
    "                nb_stay += 1\n",
    "    # Compute nb removed\n",
    "    for n1 in l1:\n",
    "        find = False\n",
    "        for n2 in l2:\n",
    "            if n1 == n2:\n",
    "                find = True\n",
    "        if not find:\n",
    "            nb_leave += 1\n",
    "    print(title + ':')\n",
    "    print(\"\\t{0} parameters kept and {1} parameters removed\".format(nb_stay, nb_leave))\n",
    "\n",
    "\n",
    "def keep_one_target(liste, target):\n",
    "    \"\"\" Allows removing multiple occurrence of target when laucnhed\n",
    "        several times\"\"\"\n",
    "    new_list = []\n",
    "    for elt in liste:\n",
    "        if elt != target:\n",
    "            new_list.append(elt)\n",
    "    new_list.append(target)\n",
    "    return new_list\n",
    "\n",
    "\n",
    "target = 'hosp'\n",
    "\n",
    "LinearRegression_keepinglist_hosp = keep_one_target(\n",
    "    LinearRegression_keepinglist_hosp, target)\n",
    "df_D31_hosp_LinReg = df_D31_hosp[LinearRegression_keepinglist_hosp]\n",
    "compare_df_columns(df_D31_hosp, df_D31_hosp_LinReg,\n",
    "            title=\"LinearRegression on '\" + target + \"' with D31\")\n",
    "\n",
    "LinearRidge_keepinglist_hosp = keep_one_target(\n",
    "    LinearRidge_keepinglist_hosp, target)\n",
    "df_D31_hosp_LinRid = df_D31_hosp[LinearRidge_keepinglist_hosp]\n",
    "compare_df_columns(df_D31_hosp, df_D31_hosp_LinRid,\n",
    "            title=\"LinearRidge on '\" + target + \"' with D31\")\n",
    "\n",
    "Neighbors_Regressor_keepinglist_hosp = keep_one_target(\n",
    "    Neighbors_Regressor_keepinglist_hosp, target)\n",
    "df_D31_hosp_NeiReg = df_D31_hosp[Neighbors_Regressor_keepinglist_hosp]\n",
    "compare_df_columns(df_D31_hosp, df_D31_hosp_NeiReg,\n",
    "            title=\"NeighborsRegression on '\" + target + \"' with D31\")\n",
    "\n",
    "target = 'rea'\n",
    "\n",
    "LinearRegression_keepinglist_rea = keep_one_target(\n",
    "    LinearRegression_keepinglist_rea, target)\n",
    "df_D31_rea_LinReg = df_D31_rea[LinearRegression_keepinglist_rea]\n",
    "compare_df_columns(df_D31_rea, df_D31_rea_LinReg,\n",
    "            title=\"LinearRegression on '\" + target + \"' with D31\")\n",
    "\n",
    "LinearRidge_keepinglist_rea = keep_one_target(\n",
    "    LinearRidge_keepinglist_rea, target)\n",
    "df_D31_rea_LinRid = df_D31_rea[LinearRidge_keepinglist_rea]\n",
    "compare_df_columns(df_D31_rea, df_D31_rea_LinRid,\n",
    "            title=\"LinearRidge on '\" + target + \"' with D31\")\n",
    "\n",
    "Neighbors_Regressor_keepinglist_rea = keep_one_target(\n",
    "    Neighbors_Regressor_keepinglist_rea, target)\n",
    "df_D31_rea_NeiReg = df_D31_rea[Neighbors_Regressor_keepinglist_rea]\n",
    "compare_df_columns(df_D31_rea, df_D31_rea_NeiReg,\n",
    "            title=\"NeighborsRegression on '\" + target + \"' with D31\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Data understanding - Refinement\n",
    "# ----------------------------------------------------------------------========\n",
    "# Create new data sets only with parameters to keep as identified\n",
    "#  here-above for the three modeling methods.\n",
    "# Built the refined dataframes\n",
    "#  \n",
    "#  At Region level\n",
    "\n",
    "target = 'hosp'\n",
    "\n",
    "LinearRegression_keepinglist_hosp = keep_one_target(\n",
    "    LinearRegression_keepinglist_hosp, target)\n",
    "df_R76_hosp_LinReg = df_R76_hosp[LinearRegression_keepinglist_hosp]\n",
    "compare_df_columns(df_R76_hosp, df_R76_hosp_LinReg,\n",
    "            title=\"LinearRegression on '\" + target + \"' with R76\")\n",
    "\n",
    "LinearRidge_keepinglist_hosp = keep_one_target(\n",
    "    LinearRidge_keepinglist_hosp, target)\n",
    "df_R76_hosp_LinRid = df_R76_hosp[LinearRidge_keepinglist_hosp]\n",
    "compare_df_columns(df_R76_hosp, df_R76_hosp_LinRid,\n",
    "            title=\"LinearRidge on '\" + target + \"' with R76\")\n",
    "\n",
    "Neighbors_Regressor_keepinglist_hosp = keep_one_target(\n",
    "    Neighbors_Regressor_keepinglist_hosp, target)\n",
    "df_R76_hosp_NeiReg = df_R76_hosp[LinearRidge_keepinglist_hosp]\n",
    "compare_df_columns(df_R76_hosp, df_R76_hosp_NeiReg,\n",
    "            title=\"NeighborRegressor on '\" + target + \"' with R76\")\n",
    "\n",
    "target = 'rea'\n",
    "\n",
    "LinearRegression_keepinglist_rea= keep_one_target(\n",
    "    LinearRegression_keepinglist_rea, target)\n",
    "df_R76_rea_LinReg = df_R76_rea[LinearRegression_keepinglist_rea]\n",
    "compare_df_columns(df_R76_rea, df_R76_rea_LinReg,\n",
    "            title=\"LinearRegression on '\" + target + \"' with R76\")\n",
    "\n",
    "LinearRidge_keepinglist_rea = keep_one_target(\n",
    "    LinearRidge_keepinglist_rea, target)\n",
    "df_R76_rea_LinRid = df_R76_rea[LinearRidge_keepinglist_rea]\n",
    "compare_df_columns(df_R76_rea, df_R76_rea_LinRid,\n",
    "            title=\"LinearRidge on '\" + target + \"' with R76\")\n",
    "\n",
    "Neighbors_Regressor_keepinglist_rea = keep_one_target(\n",
    "    Neighbors_Regressor_keepinglist_rea, target)\n",
    "df_R76_rea_NeiReg = df_R76_rea[LinearRidge_keepinglist_rea]\n",
    "compare_df_columns(df_R76_rea, df_R76_rea_NeiReg,\n",
    "            title=\"NeighborRegressor on '\" + target + \"' with R76\")\n",
    "\n",
    "\n",
    "# At France level\n",
    "\n",
    "target = 'hosp'\n",
    "\n",
    "LinearRegression_keepinglist_hosp = keep_one_target(\n",
    "    LinearRegression_keepinglist_hosp, target)\n",
    "df_Fr_hosp_LinReg = df_Fr_hosp[LinearRegression_keepinglist_hosp]\n",
    "compare_df_columns(df_Fr_hosp, df_Fr_hosp_LinReg,\n",
    "            title=\"LinearRegression on '\" + target + \"' with Fr\")\n",
    "\n",
    "LinearRidge_keepinglist_hosp = keep_one_target(\n",
    "    LinearRidge_keepinglist_hosp, target)\n",
    "df_Fr_hosp_LinRid = df_Fr_hosp[LinearRidge_keepinglist_hosp]\n",
    "compare_df_columns(df_Fr_hosp, df_Fr_hosp_LinRid,\n",
    "            title=\"LinearRidge on '\" + target + \"' with Fr\")\n",
    "\n",
    "Neighbors_Regressor_keepinglist_hosp = keep_one_target(\n",
    "    Neighbors_Regressor_keepinglist_hosp, target)\n",
    "df_Fr_hosp_NeiReg = df_Fr_hosp[LinearRidge_keepinglist_hosp]\n",
    "compare_df_columns(df_Fr_hosp, df_Fr_hosp_NeiReg,\n",
    "            title=\"NeighborRegressor on '\" + target + \"' with Fr\")\n",
    "\n",
    "target = 'rea'\n",
    "\n",
    "LinearRegression_keepinglist_rea= keep_one_target(\n",
    "    LinearRegression_keepinglist_rea, target)\n",
    "df_Fr_rea_LinReg = df_Fr_rea[LinearRegression_keepinglist_rea]\n",
    "compare_df_columns(df_Fr_rea, df_Fr_rea_LinReg,\n",
    "            title=\"LinearRegression on '\" + target + \"' with Fr\")\n",
    "\n",
    "LinearRidge_keepinglist_rea = keep_one_target(\n",
    "    LinearRidge_keepinglist_rea, target)\n",
    "df_Fr_rea_LinRid = df_Fr_rea[LinearRidge_keepinglist_rea]\n",
    "compare_df_columns(df_Fr_rea, df_Fr_rea_LinRid,\n",
    "            title=\"LinearRidge on '\" + target + \"' with Fr\")\n",
    "\n",
    "Neighbors_Regressor_keepinglist_rea = keep_one_target(\n",
    "    Neighbors_Regressor_keepinglist_rea, target)\n",
    "df_Fr_rea_NeiReg = df_Fr_rea[LinearRidge_keepinglist_rea]\n",
    "compare_df_columns(df_Fr_rea, df_Fr_rea_NeiReg,\n",
    "            title=\"NeighborRegressor on '\" + target + \"' with Fr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Data understanding - Refinement\n",
    "# ----------------------------------------------------------------------========\n",
    "# Create a function that will allows checking the impact of this change \n",
    "#  of data sets.\n",
    "\n",
    "def get_scores(df, target, sel_model=None):\n",
    "    \"\"\"\n",
    "    DESCRIPTION\n",
    "        get scores for a selected dataframe and target\n",
    "    INPUT\n",
    "        dfr  is the dataframe\n",
    "        target  is the parameter selected as answer\n",
    "    OUTPUT\n",
    "        overall_scores  is a dictionary of the dictionary's scores for \n",
    "                        all selected modeling methods.\n",
    "                   {methode1: {'r2_score': value, 'score': value},\n",
    "                    methode2: {...},\n",
    "                    ...\n",
    "                   }\n",
    "    \"\"\"\n",
    "    overall_scores = dict()\n",
    "\n",
    "    models_list = ['LinearRegression', 'Ridge', \n",
    "                'NeighborsRegressor_distance']\n",
    "\n",
    "    dfr = df.copy(deep=True)\n",
    "\n",
    "    # for every, modeling method, get scores while using every input \n",
    "    # parameter:\n",
    "    for model in models_list:\n",
    "        if (sel_model is None) or (model == sel_model):\n",
    "            scores = applying_model(dfr, model_name=model, response=target)\n",
    "            overall_scores[model] = scores\n",
    "\n",
    "    del dfr, target\n",
    "    return overall_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Data understanding - Refinement\n",
    "# ----------------------------------------------------------------------========\n",
    "# Create a function to display results, including comparison of scores\n",
    "#  before and after reducing the parameters list (refinement).\n",
    "\n",
    "def display_refinement_result(df_list, target):\n",
    "    \"\"\"\n",
    "    DESCRIPTION\n",
    "        Display result of the refinement process (reducing the number\n",
    "         of paramters per data set) by comparison before and after\n",
    "         reduction, for every model.\n",
    "    INPUT\n",
    "        df_list  is a list of two lists\n",
    "                 (one before reduction, one after reduction)\n",
    "                 ordered in the same order that the modeling methods.\n",
    "        target  is the parameter selected as response (str).\n",
    "    OUTPUT\n",
    "        none (only display and plot)\n",
    "    \"\"\"\n",
    "    models_list = ['LinearRegression', 'Ridge', \n",
    "                'NeighborsRegressor_distance']\n",
    "\n",
    "    # Get the scores for every model on its dataframe\n",
    "    scores_per_model = dict()\n",
    "    for i, model in enumerate (models_list):\n",
    "        scores = []\n",
    "        for df_sublist in df_list: # before, then after\n",
    "            scores_dict = get_scores(df_sublist[i],\n",
    "                                    target, sel_model=model)\n",
    "            scores.append(scores_dict[model]['score'])  # get only this type of score\n",
    "        scores_per_model[model] = scores\n",
    "\n",
    "    # display result\n",
    "    before_list, after_list = [], []\n",
    "    df_result = pd.DataFrame([])\n",
    "    model_list, scores_list, status_list = [], [], []\n",
    "    print('RESULTS:\\t\\t\\t\\tBefore refinement\\t After refinement')\n",
    "    for model in scores_per_model:\n",
    "        print(\"Model '\", model, \"':\", (27-len(model))*' ',\n",
    "            scores_per_model[model][0], '\\t', scores_per_model[model][1])\n",
    "        # Manage df for further display\n",
    "        for j, sts in enumerate (scores_per_model[model]):\n",
    "            model_list.append(model)\n",
    "            scores_list.append(scores_per_model[model][j])\n",
    "            if j == 0:\n",
    "                status = 'before'\n",
    "                before_list.append(scores_per_model[model][j])\n",
    "            else:\n",
    "                status = 'after'\n",
    "                after_list.append(scores_per_model[model][j])\n",
    "            status_list.append(status)\n",
    "\n",
    "    df_result['model'] = model_list\n",
    "    df_result['score'] = scores_list\n",
    "    df_result['status'] = status_list\n",
    "\n",
    "    # Plot\n",
    "    \"\"\"\n",
    "    # Not the most appropriate type of plot here.\n",
    "    fig = px.bar(df_result, x=\"status\", y=\"score\",\n",
    "                color=\"model\",\n",
    "                title=\"Comparison of scores with three modeling methods (default settings) for response '\" + target + \"'\",\n",
    "                barmode = 'group')\n",
    "    fig.show()\n",
    "    \"\"\"\n",
    "\n",
    "    x = models_list\n",
    "    plot = go.Figure(data=[go.Bar(\n",
    "        name = 'Before',\n",
    "        x = x,\n",
    "        y = before_list\n",
    "    ),\n",
    "                        go.Bar(\n",
    "        name = 'After',\n",
    "        x = x,\n",
    "        y = after_list\n",
    "    )\n",
    "    ])\n",
    "    #,\n",
    "    #layout=go.Layout(\n",
    "    #    title=go.layout.Title(text=\"Comparison of scores with three modeling methods (default settings) for response '\" + target + \"'\")\n",
    "    #))\n",
    "\n",
    "    plot.update_layout(\n",
    "        title=\"Comparison of scores with three modeling methods (default settings) for response '\" + target + \"'\",\n",
    "        xaxis_title=\"Modeling methods\",\n",
    "        yaxis_title=\"Scores\",\n",
    "        font=dict(\n",
    "            family=\"Courier New, monospace\",\n",
    "            size=18,\n",
    "            color=\"#7f7f7f\"\n",
    "        )\n",
    "    )\n",
    "    plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Data understanding - Refinement\n",
    "# ----------------------------------------------------------------------========\n",
    "# Compare the scores before/after reducing the number of parameters in\n",
    "#  the data set.\n",
    "\n",
    "target = 'hosp'\n",
    "df_list_before = [df_D31_hosp, df_D31_hosp, df_D31_hosp]\n",
    "df_list_after = [df_D31_hosp_LinReg, df_D31_hosp_LinRid,\\\n",
    "                 df_D31_hosp_NeiReg]\n",
    "df_list = [df_list_before, df_list_after]\n",
    "# display result for 'hosp'\n",
    "display_refinement_result(df_list, target)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Data understanding - Refinement\n",
    "# ----------------------------------------------------------------------========\n",
    "# Compare the scores before/after reducing the number of parameters in\n",
    "#  the data set.\n",
    "\n",
    "target = 'rea'\n",
    "df_list_before = [df_D31_rea, df_D31_rea, df_D31_rea]\n",
    "df_list_after = [df_D31_rea_LinReg, df_D31_rea_LinRid,\\\n",
    "                 df_D31_rea_NeiReg]\n",
    "df_list = [df_list_before, df_list_after]\n",
    "# display result for 'hosp'\n",
    "display_refinement_result(df_list, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Implementation - Hyperparameter tuning\n",
    "# ----------------------------------------------------------------------========\n",
    "# Define a function to identify the best hyper parameter tuning over the\n",
    "#   various modeling methods, targets and areas.\n",
    "\n",
    "def search_hyperparameters_tuning(df, sel_mode='', sel_target=''):\n",
    "    \"\"\"\n",
    "    DESCRIPTION\n",
    "        Provide information to select the best hyper-parameter tuning \n",
    "         on the selection (dataframe, model and target).\n",
    "    INPUT\n",
    "        df  is the dataframe to work on\n",
    "        sel_mode  is the name of the selected modeling method:\n",
    "                  models_list = ['LinearRegression', 'Ridge', \n",
    "                  'NeighborsRegressor_distance']\n",
    "        sel_target  is the name of the parameters used as answer.\n",
    "    OUTPUT\n",
    "        dictionary of arguments related to Random Search method:\n",
    "        Available keys: 'best_param', 'scorer'\n",
    "    \"\"\"\n",
    "\n",
    "    # source: https://scikit-learn.org/stable/modules/grid_search.html\n",
    "    # and https://scikit-learn.org/stable/auto_examples/model_selection/\n",
    "    #      plot_successive_halving_iterations.html#sphx-glr-auto-examples-\n",
    "    #      model-selection-plot-successive-halving-iterations-py\n",
    "\n",
    "    dfm = df.copy(deep=True)\n",
    "    model = None\n",
    "    parameters = []\n",
    "\n",
    "    X, y = get_X_y(dfm, sel_target)\n",
    "    # X, y = get_X_y(df_R76_hosp, 'hosp')\n",
    "    # X, y = get_X_y(df_Fr_hosp, 'hosp')\n",
    "    # X, y = get_X_y(df_D31_rea, 'rea')\n",
    "    # X, y = get_X_y(df_R76_rea, 'rea')\n",
    "    # X, y = get_X_y(df_Fr_rea, 'rea')\n",
    "\n",
    "    # Model #1\n",
    "    if sel_mode == 'LinearRegression':\n",
    "        model = LinearRegression()\n",
    "        parameters = {'fit_intercept': [True, False],\n",
    "                    'positive': [True, False]}\n",
    "    # with reduced data set:\n",
    "    # RESULT hosp D31 best_params_: {'positive': True, 'fit_intercept': False}\n",
    "    # RESULT hosp R76 best_params_: {'positive': True, 'fit_intercept': False}\n",
    "    # RESULT hosp Fr  best_params_: {'positive': True, 'fit_intercept': False}\n",
    "    # RESULT rea D31  best_params_: {'positive': True, 'fit_intercept': False}\n",
    "    # RESULT rea R76  best_params_: {'positive': True, 'fit_intercept': False}\n",
    "    # ...\n",
    "    # with not reduced data set:\n",
    "    # {'positive': True, 'fit_intercept': False}\n",
    "    # {'positive': True, 'fit_intercept': False}\n",
    "    # {'positive': True, 'fit_intercept': False}\n",
    "    # {'positive': True, 'fit_intercept': False}\n",
    "    # {'positive': True, 'fit_intercept': False}\n",
    "    # {'positive': True, 'fit_intercept': False}\n",
    "\n",
    "    # Model #2\n",
    "    if sel_mode == 'Ridge':\n",
    "        model = Ridge()  # fit_intercept=True\n",
    "        parameters = {'fit_intercept': [True, False],\n",
    "                    'alpha': [0.1, 0.5, 1, 5, 10, 20],\n",
    "                    'positive': [True, False],\n",
    "                    'max_iter': [10, 25, 50, 75, 100, 500, 600, 700, 800, 900, 1000],\n",
    "                    'tol': [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e-0, 10, 100]}\n",
    "    # with reduced data set:\n",
    "    # RESULT hosp D31 best_params: {'tol': 1e-05, 'positive': True, 'max_iter': 500, 'fit_intercept': True, 'alpha': 1}\n",
    "    #                              {'tol': 1e-05, 'positive': True, 'max_iter': 500,                        'alpha': 1}\n",
    "    # RESULT hosp R76 best_params: {'tol': 1e-05, 'positive': True, 'max_iter': 600, 'fit_intercept': True, 'alpha': 0.5}\n",
    "    #                              {'tol': 1e-05, 'positive': True, 'max_iter': 25,                         'alpha': 1}\n",
    "    # RESULT hosp Fr best_params_: {'tol': 1e-05, 'positive': True, 'max_iter': 500, 'fit_intercept': False, 'alpha': 1}\n",
    "    # RESULT rea D31  best_params: {'tol': 0.0001, 'positive': True, 'max_iter': 75, 'fit_intercept': False, 'alpha': 20}\n",
    "    # RESULT rea R76  best_params: {'tol': 0.1, 'positive': True, 'max_iter': 900, 'fit_intercept': False, 'alpha': 10}\n",
    "    # RESULT rea Fr   best_params: {'tol': 1e-05, 'positive': True, 'max_iter': 900, 'fit_intercept': False, 'alpha': 1}\n",
    "\n",
    "    # with not reduced data set:\n",
    "    # RESULT hosp D31 best_params: {'tol': 1e-05, 'positive': True, 'max_iter': 100, 'fit_intercept': True, 'alpha': 1}\n",
    "    # RESULT hosp R76 best_params: {'tol': 1e-05, 'positive': True, 'max_iter': 500, 'fit_intercept': True, 'alpha': 1}\n",
    "    # RESULT hosp Fr best_params_: {'tol': 0.0001, 'positive': True, 'max_iter': 900, 'fit_intercept': False, 'alpha': 1}\n",
    "    # RESULT hosp Fr best_params_: {'tol': 0.0001, 'positive': True, 'max_iter': 500,                  True   'alpha': 1}\n",
    "    # RESULT rea D31  best_params: {'tol': 1.0, 'positive': True, 'max_iter': 10, 'fit_intercept': True, 'alpha': 0.1}\n",
    "    # RESULT rea R76  best_params: {'tol': 1e-05, 'positive': True, 'max_iter': 25, 'fit_intercept': False, 'alpha': 0.5}\n",
    "    # RESULT rea R76  best_params: {'tol': 1e-05, 'positive': True, 'max_iter': 600,                 True   'alpha': 0.1}\n",
    "    # RESULT rea Fr   best_params: {'tol': 0.0001, 'positive': True, 'max_iter': 500, 'fit_intercept': True, 'alpha': 1}\n",
    "\n",
    "\n",
    "    # Model #3\n",
    "    if sel_mode == 'NeighborsRegressor_distance':\n",
    "        model = neighbors.KNeighborsRegressor(weights='distance')\n",
    "        parameters = {'n_neighbors': [1, 2, 4, 6, 8, 10, 20, 50, 100, 500, 600, 700, 800, 900, 1000],\n",
    "                    'p': [1, 2],\n",
    "                    'n_jobs': [1, 2, 3, 4, 5, 6, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "                    }\n",
    "        #(model.fit(X, y)).get_params().keys()\n",
    "\n",
    "    # with reduced data set:\n",
    "    # RESULT hosp D31 best_params_: {'p': 1, 'n_neighbors': 500, 'n_jobs': 4}\n",
    "    # RESULT hosp R76 best_params_: {'p': 1, 'n_neighbors': 900, 'n_jobs': 4}\n",
    "    # RESULT hosp Fr  best_params_: {'p': 1, 'n_neighbors': 900, 'n_jobs': 4}\n",
    "    # RESULT rea D31  best_params_: {'p': 1, 'n_neighbors': 800, 'n_jobs': 50}\n",
    "    # RESULT rea R76  best_params_: {'p': 1, 'n_neighbors': 900, 'n_jobs': 4}\n",
    "    # RESULT rea Fr   best_params_: {'p': 1, 'n_neighbors': 900, 'n_jobs': 4}\n",
    "\n",
    "    # with not reduced data set:\n",
    "    # RESULT hosp D31 best_params_: {'p': 2, 'n_neighbors': 900, 'n_jobs': 3}\n",
    "    #                               {     1                 500  'n_jobs': 90}\n",
    "    #                               {     1  'n_neighbors': 900  90}\n",
    "    # RESULT hosp R76 best_params_: {'p': 1, 'n_neighbors': 900, 'n_jobs': 4}\n",
    "    #                               {     1                 500  'n_jobs': 90}\n",
    "    # RESULT hosp Fr  best_params_: {'p': 1, 'n_neighbors': 900, 'n_jobs': 4}\n",
    "    #                               {     1                 500  'n_jobs': 90}\n",
    "    # RESULT rea D31  best_params_: {'p': 1, 'n_neighbors': 500, 'n_jobs': 3}\n",
    "    #                               {     1                 500  'n_jobs': 90}\n",
    "    # RESULT rea R76  best_params_: {'p': 1, 'n_neighbors': 900, 'n_jobs': 4}\n",
    "    #                               {     1                 500  'n_jobs': 90}\n",
    "    # RESULT rea Fr   best_params_: {'p': 1, 'n_neighbors': 900, 'n_jobs': 4}\n",
    "    #                               {     1                 500  'n_jobs': 90}\n",
    "    #                               {     1  'n_neighbors': 900  90}\n",
    "\n",
    "    # Search\n",
    "    if model is not None:\n",
    "        sh = HalvingRandomSearchCV(model, parameters,\n",
    "                                min_resources='smallest').fit(X, y)  # min_resources='exhaust'\n",
    "    else:\n",
    "        sh = None\n",
    "\n",
    "    #for param in rnd_search.get_params().keys():\n",
    "    #    print(param)\n",
    "    #print('cv_results_\\n', sh.cv_results_)\n",
    "    #print('candidates\\n', sh.best_estimator_)\n",
    "    # print('best_params_:\\n', sh.best_params_)\n",
    "    # print('scorer_:\\n', sh.scorer_)\n",
    "\n",
    "    del df, sel_mode, sel_target, dfm, model, parameters, X, y\n",
    "    return {'best_param': sh.best_params_, 'scorer': sh.scorer_}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Implementation - Hyperparameter tuning\n",
    "# ----------------------------------------------------------------------========\n",
    "# Search for the best hyper parameter tuning over the various modeling\n",
    "#  methods, targets and areas.\n",
    "\n",
    "def run_list_hyperparameters_tuning(df_liste=[], sel_mode='', sel_target=''):\n",
    "    \"\"\"\n",
    "    DESCRIPTION\n",
    "        Display information related to lists of selection\n",
    "         (dataframe, model and target) for hyper-parameter tuning.\n",
    "    INPUT\n",
    "        df_liste  is a liste of dataframes to work on\n",
    "                  with structure for targets and models\n",
    "                  [ [tgt1_model1, tgt1_model2 ...],\n",
    "                    [tgt2_model1, tgt2_model2 ...] ]\n",
    "        sel_mode  is the name of the selected modeling method:\n",
    "                  models_list = ['LinearRegression', 'Ridge', \n",
    "                  'NeighborsRegressor_distance']\n",
    "        sel_target  is the name of the parameters used as answer.\n",
    "    OUTPUT\n",
    "        overall_results_dict  is a dictionary with all result per\n",
    "                              model and target\n",
    "                {target1: {model1: result1, model2: result2, ...},\n",
    "                 target2: {...}, ... }\n",
    "    \"\"\"\n",
    "    overall_results_dict = {}\n",
    "\n",
    "    for t, target in enumerate (targets_list):\n",
    "        overall_results_dict[target] = {}\n",
    "        for m, model in enumerate (models_list):\n",
    "            print(\"\\n>> Target:\", target, \"- Model:\", model)\n",
    "            start = time.perf_counter()\n",
    "            result_dict = search_hyperparameters_tuning(\n",
    "                            df_list[t][m],\n",
    "                            sel_mode=model,\n",
    "                            sel_target=target)\n",
    "            # store the result\n",
    "            overall_results_dict[target][model] = result_dict\n",
    "\n",
    "            elapsed = time.perf_counter() - start\n",
    "            print(\">> Time:\", elapsed)\n",
    "            print(\">> Result:\", result_dict)\n",
    "\n",
    "    return overall_results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Implementation - Hyperparameter tuning\n",
    "# ----------------------------------------------------------------------========\n",
    "# Search for the best hyper parameter tuning over the various modeling\n",
    "#  methods, targets and areas.\n",
    "\n",
    "# Search at department level\n",
    "\n",
    "targets_list = ['hosp', 'rea']\n",
    "\n",
    "models_list = ['LinearRegression', 'Ridge',\n",
    "               'NeighborsRegressor_distance']\n",
    "df_list = [\n",
    "    [df_D31_hosp_LinReg, df_D31_hosp_LinRid, df_D31_hosp_NeiReg],\\\n",
    "    [df_D31_rea_LinReg, df_D31_rea_LinRid, df_D31_rea_NeiReg] ]\n",
    "# use the data set specially refined for the model and target.\n",
    "\n",
    "hyperparamtuning_results_D31 = run_list_hyperparameters_tuning(\n",
    "    df_liste=df_list, sel_mode=models_list, sel_target=targets_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESULT for department D31\n",
    ">> Target: hosp - Model: LinearRegression\n",
    ">> Time: 0.11591849999967963\n",
    ">> Result: {'best_param': {'positive': True, 'fit_intercept': False}, 'scorer': <function _passthrough_scorer at 0x000001E5195D4318>}\n",
    "\n",
    ">> Target: hosp - Model: Ridge\n",
    ">> Time: 1.7555947999999262\n",
    ">> Result: {'best_param': {'tol': 10, 'positive': False, 'max_iter': 75, 'fit_intercept': True, 'alpha': 20}, 'scorer': <function _passthrough_scorer at 0x000001E5195D4318>}\n",
    ">> with warning messages\n",
    "\n",
    ">> Target: hosp - Model: NeighborsRegressor_distance\n",
    "> Time: 25.86618610000005\n",
    ">> Result: {'best_param': {'p': 2, 'n_neighbors': 700, 'n_jobs': 10}, 'scorer': <function _passthrough_scorer at 0x000001E5195D4318>}\n",
    ">> with warning messages\n",
    "\n",
    ">> Target: rea - Model: LinearRegression\n",
    ">> Time: 0.10736890000043786\n",
    ">> Result: {'best_param': {'positive': True, 'fit_intercept': False}, 'scorer': <function _passthrough_scorer at 0x000001E5195D4318>}\n",
    "\n",
    ">> Target: rea - Model: Ridge\n",
    ">> Time: 1.846445200000744\n",
    ">> Result: {'best_param': {'tol': 1e-05, 'positive': True, 'max_iter': 800, 'fit_intercept': True, 'alpha': 10}, 'scorer': <function _passthrough_scorer at 0x000001E5195D4318>}\n",
    ">> with warning messages\n",
    "\n",
    ">> Target: rea - Model: NeighborsRegressor_distance\n",
    ">> Time: 22.611654600000293\n",
    ">> Result: {'best_param': {'p': 2, 'n_neighbors': 900, 'n_jobs': 1}, 'scorer': <function _passthrough_scorer at 0x000001E5195D4318>}\n",
    ">> with warning messages\n",
    "\n",
    "\n",
    "# RESUME\n",
    "Model: LinearRegression\n",
    "hosp    Result: {'best_param': {'positive': True, 'fit_intercept': False}, ...}\n",
    "rea     Result: {'best_param': {'positive': True, 'fit_intercept': False}, ...}\n",
    ">> common settings\n",
    "\n",
    "Model: Ridge\n",
    "hosp    Result: {'best_param': {'tol':    10, 'positive': False,  'max_iter': 75, 'fit_intercept': True, 'alpha': 20}, ...}\n",
    "rea     Result: {'best_param': {'tol': 1e-05, 'positive': True,  'max_iter': 800, 'fit_intercept': True, 'alpha': 10}, ...}\n",
    ">> Different settings\n",
    "\n",
    "Model: NeighborsRegressor_distance\n",
    "hosp    Result: {'best_param': {'p': 2, 'n_neighbors': 700, 'n_jobs': 10}, ...}\n",
    "rea     Result: {'best_param': {'p': 2, 'n_neighbors': 900,  'n_jobs': 1}, ...}\n",
    ">> Rather close settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Implementation - Hyperparameter tuning\n",
    "# ----------------------------------------------------------------------========\n",
    "# Search for the best hyper parameter tuning over the various modeling\n",
    "#  methods, targets and areas.\n",
    "\n",
    "# Search at region level\n",
    "\n",
    "targets_list = ['hosp', 'rea']\n",
    "\n",
    "models_list = ['LinearRegression', 'Ridge',\n",
    "               'NeighborsRegressor_distance']\n",
    "df_list = [\n",
    "    [df_R76_hosp_LinReg, df_R76_hosp_LinRid, df_R76_hosp_NeiReg],\\\n",
    "    [df_R76_rea_LinReg, df_R76_rea_LinRid, df_R76_rea_NeiReg] ]\n",
    "# use the data set specially refined for the model and target.\n",
    "\n",
    "# hyperparamtuning_results_R76 = run_list_hyperparameters_tuning(\n",
    "#    df_liste=df_list, sel_mode=models_list, sel_target=targets_list)\n",
    "\n",
    "# No computation at France level because it takes a long time \n",
    "#  for the Region. I'm gonna proceed differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Implementation - Hyperparameter tuning\n",
    "# ----------------------------------------------------------------------========\n",
    "# Proceed for searching searching method for Neighbors Regressor\n",
    "# Define function to allows studying the one by one hyper parameter\n",
    "#  tuning study and display related score.\n",
    "\n",
    "def return_df(dfs, target, area):\n",
    "    \"\"\"\n",
    "    DESCRIPTION\n",
    "        Return the dataframe in accordance wit the target and\n",
    "        the area.\n",
    "    INPUT\n",
    "        dfs  is a dictionary of the dataframe customized and\n",
    "                refined by area.\n",
    "        target  is the name (str) of the parameter used as\n",
    "                answer for modeling.\n",
    "        area  is the name (str) of the considered area:\n",
    "                Department 31, Region 76 or France\n",
    "    OUTPUT\n",
    "        sel_def = dataframe identified\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        sel_def = dfs[target][area]\n",
    "    except:\n",
    "        print('Unable to get the appropriate refined df.')\n",
    "        sel_def = None\n",
    "\n",
    "    return sel_def\n",
    "\n",
    "\n",
    "def param_study_NeighborReg(dfs, target, area):\n",
    "    \"\"\"\n",
    "    DESCRIPTION\n",
    "\n",
    "    INPUT\n",
    "        dfs  is a dictionary of the dataframe customized and\n",
    "                refined by area.\n",
    "        target  is the name (str) of the parameter used as\n",
    "                answer for modeling.\n",
    "        area  is the name (str) of the considered area:\n",
    "                Department 31, Region 76 or France\n",
    "    OUTPUT\n",
    "        display scatter graph of score while changing value  \n",
    "        of their input tuning parameters.\n",
    "    \"\"\"\n",
    "    m_name = \"NeighborsRegressor\"\n",
    "\n",
    "    n_neighbors = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20]  #,\\\n",
    "            # 30, 40, 50, 100, 200, 300, 400, 500, 600, 700,\\\n",
    "            # 800, 900, 1000]\n",
    "    p_values = [1, 2]\n",
    "    n_jobs = [1, 2, 3, 4, 5, 6, 10, 20, 30, 40, 50, 60, 70,\\\n",
    "                80, 90, 100]\n",
    "\n",
    "    df_hosp1 = pd.DataFrame([])\n",
    "    df_hosp2 = pd.DataFrame([])\n",
    "    df_hosp3 = pd.DataFrame([])\n",
    "\n",
    "    df = return_df(dfs, target, area)\n",
    "\n",
    "    X, y = get_X_y(df, target)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                    test_size=0.3,\n",
    "                                    random_state=42)\n",
    "\n",
    "    scores1, scores2 = [], []\n",
    "    for n in n_neighbors:\n",
    "        model = neighbors.KNeighborsRegressor(weights='distance',\n",
    "                n_neighbors=n,\n",
    "                p=1,\n",
    "                n_jobs=None)\n",
    "        model.fit(X_train, y_train)\n",
    "        try:\n",
    "            score_value = model.score(X_test, y_test)\n",
    "        except:\n",
    "            score_value = np.nan\n",
    "        scores1.append(score_value)\n",
    "        model = neighbors.KNeighborsRegressor(weights='distance',\n",
    "                n_neighbors=n,\n",
    "                p=2,\n",
    "                n_jobs=None)\n",
    "        model.fit(X_train, y_train)\n",
    "        try:\n",
    "            score_value = model.score(X_test, y_test)\n",
    "        except:\n",
    "            score_value = np.nan\n",
    "        scores2.append(score_value)\n",
    "    df_hosp1['n'] = n_neighbors\n",
    "    df_hosp1['score1'] = scores1\n",
    "    df_hosp1['score2'] = scores2\n",
    "\n",
    "    scores1, scores2 = [], []\n",
    "    for p_value in p_values:\n",
    "        model = neighbors.KNeighborsRegressor(weights='distance',\n",
    "                n_neighbors=4,\n",
    "                p=p_value,\n",
    "                n_jobs=None)\n",
    "        model.fit(X_train, y_train)\n",
    "        try:\n",
    "            score_value = model.score(X_test, y_test)\n",
    "        except:\n",
    "            score_value = np.nan\n",
    "        scores1.append(score_value)\n",
    "        model = neighbors.KNeighborsRegressor(weights='distance',\n",
    "                n_neighbors=5,\n",
    "                p=p_value,\n",
    "                n_jobs=None)\n",
    "        model.fit(X_train, y_train)\n",
    "        try:\n",
    "            score_value = model.score(X_test, y_test)\n",
    "        except:\n",
    "            score_value = np.nan\n",
    "        scores2.append(score_value)\n",
    "    df_hosp2['n'] = p_values\n",
    "    df_hosp2['score1'] = scores1\n",
    "    df_hosp2['score2'] = scores2\n",
    "\n",
    "    scores1, scores2 = [], []\n",
    "    for n in n_jobs:\n",
    "        model = neighbors.KNeighborsRegressor(weights='distance',\n",
    "                n_neighbors=4,\n",
    "                p=1,\n",
    "                n_jobs=n)\n",
    "        model.fit(X_train, y_train)\n",
    "        try:\n",
    "            score_value = model.score(X_test, y_test)\n",
    "        except:\n",
    "            score_value = np.nan\n",
    "        scores1.append(score_value)\n",
    "        model = neighbors.KNeighborsRegressor(weights='distance',\n",
    "                n_neighbors=5,\n",
    "                p=2,\n",
    "                n_jobs=n)\n",
    "        model.fit(X_train, y_train)\n",
    "        try:\n",
    "            score_value = model.score(X_test, y_test)\n",
    "        except:\n",
    "            score_value = np.nan\n",
    "        scores2.append(score_value)\n",
    "    df_hosp3['n'] = n_jobs\n",
    "    df_hosp3['score1'] = scores1\n",
    "    df_hosp3['score2'] = scores2\n",
    "\n",
    "    # plot result\n",
    "    title_base = \"Hyper-parameters tuning on \" +m_name+\" for target\"\n",
    "    title = title_base + \" '\" + target + \"' (\" + area + \")\"\n",
    "\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    plt.title(title)\n",
    "\n",
    "    # Plot a graph for every label of the x list\n",
    "    plt.subplot(1, 3, 1)\n",
    "    #plt = fig.add_subplot(111)\n",
    "    x = df_hosp1['n']\n",
    "    y = df_hosp1['score1']\n",
    "    y2 = df_hosp1['score2']\n",
    "    plt.scatter(x, y, c='b', marker='o', label='p=1')\n",
    "    plt.scatter(x, y2, c='g', marker='s', label='p=2')\n",
    "    plt.title('')\n",
    "    plt.xlabel('n_neighbors')\n",
    "    plt.ylabel('score')\n",
    "    plt.legend(loc='upper right')\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    x = df_hosp2['n']\n",
    "    y = df_hosp2['score1']\n",
    "    y2 = df_hosp2['score2']\n",
    "    plt.scatter(x, y, c='b', marker='o', label='neighbors=4')\n",
    "    plt.scatter(x, y2, c='g', marker='s', label='neighbors=5')\n",
    "    plt.title('')\n",
    "    plt.xlabel('n_p')\n",
    "    plt.ylabel('score')\n",
    "    plt.legend(loc='upper right')\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    x = df_hosp3['n']\n",
    "    y = df_hosp3['score1']\n",
    "    y2 = df_hosp3['score2']\n",
    "    plt.scatter(x, y, c='b', marker='o', label='p=1 / neighbors=4')\n",
    "    plt.scatter(x, y2, c='g', marker='s', label='p=2 / neighbors=5')\n",
    "    plt.title('')\n",
    "    plt.xlabel('n_jobs')\n",
    "    plt.ylabel('score')\n",
    "    plt.legend(loc='center left')\n",
    "\n",
    "    plt.suptitle(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Implementation - Hyperparameter tuning\n",
    "# ----------------------------------------------------------------------========\n",
    "# Proceed for searching searching method for Linear Regressor\n",
    "# Define function to allows studying the one by one hyper parameter\n",
    "#  tuning study and display related score.\n",
    "\n",
    "def param_study_LinearReg(dfs, target, area):\n",
    "    \"\"\"\n",
    "    DESCRIPTION\n",
    "\n",
    "    INPUT\n",
    "        dfs  is a dictionary of the dataframe customized and\n",
    "                refined by area.\n",
    "        target  is the name (str) of the parameter used as\n",
    "                answer for modeling.\n",
    "        area  is the name (str) of the considered area:\n",
    "                Department 31, Region 76 or France\n",
    "    OUTPUT\n",
    "        display scatter graph of score while changing value  \n",
    "        of their input tuning parameters.\n",
    "    \"\"\"\n",
    "    m_name = \"LinearRegressor\"\n",
    "\n",
    "    fit_values = [True, False]\n",
    "    positive_values = [True, False]\n",
    "\n",
    "    df_hosp1 = pd.DataFrame([])\n",
    "    df_hosp2 = pd.DataFrame([])\n",
    "    df_hosp3 = pd.DataFrame([])\n",
    "\n",
    "    df = return_df(dfs, target, area)\n",
    "\n",
    "    X, y = get_X_y(df, target)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                    test_size=0.3,\n",
    "                                    random_state=42)\n",
    "\n",
    "    scores1, scores2 = [], []\n",
    "    for fit_value in fit_values:\n",
    "        model = LinearRegression(fit_intercept=fit_value,\n",
    "                                 positive=True)\n",
    "        model.fit(X_train, y_train)\n",
    "        try:\n",
    "            score_value = model.score(X_test, y_test)\n",
    "        except:\n",
    "            score_value = np.nan\n",
    "        scores1.append(score_value)\n",
    "        model = LinearRegression(fit_intercept=fit_value,\n",
    "                                 positive=False)\n",
    "        model.fit(X_train, y_train)\n",
    "        try:\n",
    "            score_value = model.score(X_test, y_test)\n",
    "        except:\n",
    "            score_value = np.nan\n",
    "        scores2.append(score_value)\n",
    "    df_hosp1['n'] = list(map(int, fit_values))  # convert boolean to int\n",
    "    df_hosp1['score1'] = scores1\n",
    "    df_hosp1['score2'] = scores2\n",
    "\n",
    "    scores1, scores2 = [], []\n",
    "    for positive_value in positive_values:\n",
    "        model = LinearRegression(fit_intercept=True,\n",
    "                                 positive=positive_value)\n",
    "        model.fit(X_train, y_train)\n",
    "        try:\n",
    "            score_value = model.score(X_test, y_test)\n",
    "        except:\n",
    "            score_value = np.nan\n",
    "        scores1.append(score_value)\n",
    "        model = LinearRegression(fit_intercept=False,\n",
    "                                 positive=positive_value)\n",
    "        model.fit(X_train, y_train)\n",
    "        try:\n",
    "            score_value = model.score(X_test, y_test)\n",
    "        except:\n",
    "            score_value = np.nan\n",
    "        scores2.append(score_value)\n",
    "    # convert boolean to int\n",
    "    df_hosp2['n'] = list(map(int, positive_values))\n",
    "    \n",
    "    df_hosp2['score1'] = scores1\n",
    "    df_hosp2['score2'] = scores2\n",
    "\n",
    "\n",
    "    # plot result\n",
    "    title_base = \"Hyper-parameters tuning on \" +m_name+\" for target\"\n",
    "    title = title_base + \" '\" + target + \"' (\" + area + \")\"\n",
    "\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    plt.title(title)\n",
    "\n",
    "    # Plot a graph for every label of the x list\n",
    "    plt.subplot(1, 2, 1)\n",
    "    #plt = fig.add_subplot(111)\n",
    "    x = df_hosp1['n']\n",
    "    y = df_hosp1['score1']\n",
    "    y2 = df_hosp1['score2']\n",
    "    plt.scatter(x, y, c='b', marker='o', label='positive=True')\n",
    "    plt.scatter(x, y2, c='g', marker='s', label='positive=False')\n",
    "    plt.title('')\n",
    "    plt.xlabel('fit')\n",
    "    plt.ylabel('score')\n",
    "    plt.legend(loc='upper center')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    x = df_hosp2['n']\n",
    "    y = df_hosp2['score1']\n",
    "    y2 = df_hosp2['score2']\n",
    "    plt.scatter(x, y, c='b', marker='o', label='fit_intercept=True')\n",
    "    plt.scatter(x, y2, c='g', marker='s', label='fit_intercept=False')\n",
    "    plt.title('')\n",
    "    plt.xlabel('positive')\n",
    "    plt.ylabel('score')\n",
    "    plt.legend(loc='upper right')\n",
    "\n",
    "    plt.suptitle(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Implementation - Hyperparameter tuning\n",
    "# ----------------------------------------------------------------------========\n",
    "# Proceed for searching searching method for Linear Regressor\n",
    "# Define function to allows studying the one by one hyper parameter\n",
    "#  tuning study and display related score.\n",
    "\n",
    "def ident_log_scale(lst):\n",
    "    \"\"\"\n",
    "    DESCRIPTION \n",
    "        identify if values of a list should be plot on a log scale or\n",
    "         not.\n",
    "    INPUT\n",
    "        lst  is a list of value\n",
    "    OUTPUT\n",
    "        log_sts  is a boolean: True=log, False=not log\n",
    "    \"\"\"\n",
    "    log_sts = False\n",
    "    for i in range(len(lst)-1):\n",
    "        if lst[i+1] != 0:\n",
    "            tx = abs(lst[i]/lst[i+1])\n",
    "            if (tx >= 10) or (tx <= 0.1):\n",
    "                log_sts = True\n",
    "    del lst\n",
    "    return log_sts\n",
    "\n",
    "\n",
    "def param_study_LinearRidge(dfs, target, area):\n",
    "    \"\"\"\n",
    "    DESCRIPTION\n",
    "\n",
    "    INPUT\n",
    "        dfs  is a dictionary of the dataframe customized and\n",
    "                refined by area.\n",
    "        target  is the name (str) of the parameter used as\n",
    "                answer for modeling.\n",
    "        area  is the name (str) of the considered area:\n",
    "                Department 31, Region 76 or France\n",
    "    OUTPUT\n",
    "        display scatter graph of score while changing value  \n",
    "        of their input tuning parameters.\n",
    "    \"\"\"\n",
    "    m_name = \"LinearRidge\"\n",
    "\n",
    "    fit_intercept_values = [True, False]\n",
    "    positive_values = [True, False]\n",
    "    alpha_values = [0.1, 0.5, 1, 5, 10, 20]\n",
    "    max_iter_values = [10, 25, 50, 75, 100, 500, 600, 700, 800, 900, 1000]\n",
    "    tol_values = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e-0, 10, 100]\n",
    "\n",
    "    df_hosp1 = pd.DataFrame([])\n",
    "    df_hosp2 = pd.DataFrame([])\n",
    "    df_hosp3 = pd.DataFrame([])\n",
    "    df_hosp4 = pd.DataFrame([])\n",
    "    df_hosp5 = pd.DataFrame([])\n",
    "\n",
    "    df = return_df(dfs, target, area)\n",
    "\n",
    "    X, y = get_X_y(df, target)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                    test_size=0.3,\n",
    "                                    random_state=42)\n",
    "\n",
    "    scores1, scores2 = [], []\n",
    "    for fit_intercept_value in fit_intercept_values:\n",
    "        model = Ridge(alpha=1,\n",
    "                    fit_intercept=fit_intercept_value,\n",
    "                    positive=True,\n",
    "                    max_iter=900,\n",
    "                    tol=1\n",
    "                    )\n",
    "        model.fit(X_train, y_train)\n",
    "        try:\n",
    "            score_value = model.score(X_test, y_test)\n",
    "        except:\n",
    "            score_value = np.nan\n",
    "        scores1.append(score_value)\n",
    "        model = Ridge(alpha=1,\n",
    "                    fit_intercept=fit_intercept_value,\n",
    "                    positive=False,\n",
    "                    max_iter=900,\n",
    "                    tol=1\n",
    "                    )\n",
    "        model.fit(X_train, y_train)\n",
    "        try:\n",
    "            score_value = model.score(X_test, y_test)\n",
    "        except:\n",
    "            score_value = np.nan\n",
    "        scores2.append(score_value)\n",
    "    # convert boolean to int\n",
    "    df_hosp1['n'] = list(map(int, fit_intercept_values))\n",
    "    df_hosp1['score1'] = scores1\n",
    "    df_hosp1['score2'] = scores2\n",
    "\n",
    "    scores1, scores2 = [], []\n",
    "    for alpha_value in alpha_values:\n",
    "        model = Ridge(alpha=alpha_value,\n",
    "                    fit_intercept=True,\n",
    "                    positive=True,\n",
    "                    max_iter=900,\n",
    "                    tol=1\n",
    "                    )\n",
    "        model.fit(X_train, y_train)\n",
    "        try:\n",
    "            score_value = model.score(X_test, y_test)\n",
    "        except:\n",
    "            score_value = np.nan\n",
    "        scores1.append(score_value)\n",
    "        model = Ridge(alpha=alpha_value,\n",
    "                    fit_intercept=True,\n",
    "                    positive=False,\n",
    "                    max_iter=900,\n",
    "                    tol=1\n",
    "                    )\n",
    "        model.fit(X_train, y_train)\n",
    "        try:\n",
    "            score_value = model.score(X_test, y_test)\n",
    "        except:\n",
    "            score_value = np.nan\n",
    "        scores2.append(score_value)\n",
    "    df_hosp2['n'] = alpha_values\n",
    "    df_hosp2['score1'] = scores1\n",
    "    df_hosp2['score2'] = scores2\n",
    "\n",
    "    scores1, scores2 = [], []\n",
    "    for max_iter_value in max_iter_values:\n",
    "        model = Ridge(alpha=1,\n",
    "                    fit_intercept=True,\n",
    "                    positive=True,\n",
    "                    max_iter=max_iter_value,\n",
    "                    tol=1\n",
    "                    )\n",
    "        model.fit(X_train, y_train)\n",
    "        try:\n",
    "            score_value = model.score(X_test, y_test)\n",
    "        except:\n",
    "            score_value = np.nan\n",
    "        scores1.append(score_value)\n",
    "        model = Ridge(alpha=1,\n",
    "                    fit_intercept=True,\n",
    "                    positive=False,\n",
    "                    max_iter=max_iter_value,\n",
    "                    tol=1\n",
    "                    )\n",
    "        model.fit(X_train, y_train)\n",
    "        try:\n",
    "            score_value = model.score(X_test, y_test)\n",
    "        except:\n",
    "            score_value = np.nan\n",
    "        scores2.append(score_value)\n",
    "    df_hosp3['n'] = max_iter_values\n",
    "    df_hosp3['score1'] = scores1\n",
    "    df_hosp3['score2'] = scores2\n",
    "\n",
    "    scores1, scores2 = [], []\n",
    "    for tol_value in tol_values:\n",
    "        model = Ridge(alpha=1,\n",
    "                    fit_intercept=True,\n",
    "                    positive=True,\n",
    "                    max_iter=900,\n",
    "                    tol=tol_value\n",
    "                    )\n",
    "        model.fit(X_train, y_train)\n",
    "        try:\n",
    "            score_value = model.score(X_test, y_test)\n",
    "        except:\n",
    "            score_value = np.nan\n",
    "        scores1.append(score_value)\n",
    "        model = Ridge(alpha=1,\n",
    "                    fit_intercept=True,\n",
    "                    positive=False,\n",
    "                    max_iter=900,\n",
    "                    tol=tol_value\n",
    "                    )\n",
    "        model.fit(X_train, y_train)\n",
    "        try:\n",
    "            score_value = model.score(X_test, y_test)\n",
    "        except:\n",
    "            score_value = np.nan\n",
    "        scores2.append(score_value)\n",
    "    df_hosp4['n'] = tol_values\n",
    "    df_hosp4['score1'] = scores1\n",
    "    df_hosp4['score2'] = scores2\n",
    "\n",
    "    scores1, scores2 = [], []\n",
    "    for positive_value in positive_values:\n",
    "        model = Ridge(alpha=1,\n",
    "                    fit_intercept=True,\n",
    "                    positive=positive_value,\n",
    "                    max_iter=900,\n",
    "                    tol=1\n",
    "                    )\n",
    "        model.fit(X_train, y_train)\n",
    "        try:\n",
    "            score_value = model.score(X_test, y_test)\n",
    "        except:\n",
    "            score_value = np.nan\n",
    "        scores1.append(score_value)\n",
    "        model = Ridge(alpha=1,\n",
    "                    fit_intercept=False,\n",
    "                    positive=positive_value,\n",
    "                    max_iter=900,\n",
    "                    tol=1\n",
    "                    )\n",
    "        model.fit(X_train, y_train)\n",
    "        try:\n",
    "            score_value = model.score(X_test, y_test)\n",
    "        except:\n",
    "            score_value = np.nan\n",
    "        scores2.append(score_value)\n",
    "    # convert boolean to int\n",
    "    df_hosp5['n'] = list(map(int, positive_values))\n",
    "    df_hosp5['score1'] = scores1\n",
    "    df_hosp5['score2'] = scores2\n",
    "\n",
    "    # plot result\n",
    "    title_base = \"Hyper-parameters tuning on \" +m_name+\" for target\"\n",
    "    title = title_base + \" '\" + target + \"' (\" + area + \")\"\n",
    "\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    plt.title(title)\n",
    "\n",
    "    # Plot a graph for every label of the x list\n",
    "    plt.subplot(1, 5, 1)\n",
    "    #plt = fig.add_subplot(111)\n",
    "    x = df_hosp1['n']\n",
    "    y = df_hosp1['score1']\n",
    "    y2 = df_hosp1['score2']\n",
    "    plt.scatter(x, y, c='b', marker='o', label='positive=True')\n",
    "    plt.scatter(x, y2, c='g', marker='s', label='positive=False')\n",
    "    x_log = ident_log_scale(x)\n",
    "    y_log = ident_log_scale(y)\n",
    "    y2_log = ident_log_scale(y2)\n",
    "    if x_log:\n",
    "        plt.xscale(\"log\")\n",
    "    if y_log or y2_log:\n",
    "        plt.yscale(\"log\")\n",
    "    plt.title('')\n",
    "    plt.xlabel('fit_intercept')\n",
    "    plt.ylabel('score')\n",
    "    plt.legend(loc='upper center')\n",
    "\n",
    "    plt.subplot(1, 5, 2)\n",
    "    x = df_hosp2['n']\n",
    "    y = df_hosp2['score1']\n",
    "    y2 = df_hosp2['score2']\n",
    "    plt.scatter(x, y, c='b', marker='o', label='positive=True')\n",
    "    plt.scatter(x, y2, c='g', marker='s', label='positive=False')\n",
    "    x_log = ident_log_scale(x)\n",
    "    y_log = ident_log_scale(y)\n",
    "    y2_log = ident_log_scale(y2)\n",
    "    if x_log:\n",
    "        plt.xscale(\"log\")\n",
    "    if y_log or y2_log:\n",
    "        plt.yscale(\"log\")\n",
    "    plt.title('')\n",
    "    plt.xlabel('alpha')\n",
    "    plt.ylabel('score')\n",
    "    plt.legend(loc='upper right')\n",
    "\n",
    "    plt.subplot(1, 5, 3)\n",
    "    x = df_hosp3['n']\n",
    "    y = df_hosp3['score1']\n",
    "    y2 = df_hosp3['score2']\n",
    "    plt.scatter(x, y, c='b', marker='o', label='positive=True')\n",
    "    plt.scatter(x, y2, c='g', marker='s', label='positive=False')\n",
    "    x_log = ident_log_scale(x)\n",
    "    y_log = ident_log_scale(y)\n",
    "    y2_log = ident_log_scale(y2)\n",
    "    if x_log:\n",
    "        plt.xscale(\"log\")\n",
    "    if y_log or y2_log:\n",
    "        plt.yscale(\"log\")\n",
    "    plt.title('')\n",
    "    plt.xlabel('max_iter')\n",
    "    plt.ylabel('score')\n",
    "    plt.legend(loc='center left')\n",
    "\n",
    "    plt.subplot(1, 5, 4)\n",
    "    x = df_hosp4['n']\n",
    "    y = df_hosp4['score1']\n",
    "    y2 = df_hosp4['score2']\n",
    "    plt.scatter(x, y, c='b', marker='o', label='positive=True')\n",
    "    plt.scatter(x, y2, c='g', marker='s', label='positive=False')\n",
    "    x_log = ident_log_scale(x)\n",
    "    y_log = ident_log_scale(y)\n",
    "    y2_log = ident_log_scale(y2)\n",
    "    if x_log:\n",
    "        plt.xscale(\"log\")\n",
    "    if y_log or y2_log:\n",
    "        plt.yscale(\"log\")\n",
    "    plt.title('')\n",
    "    plt.xlabel('tol')\n",
    "    plt.ylabel('score')\n",
    "    plt.legend(loc='center left')\n",
    "\n",
    "    plt.subplot(1, 5, 5)\n",
    "    x = df_hosp5['n']\n",
    "    y = df_hosp5['score1']\n",
    "    y2 = df_hosp5['score2']\n",
    "    plt.scatter(x, y, c='b', marker='o', label='fit_intercept=True')\n",
    "    plt.scatter(x, y2, c='g', marker='s', label='fit_intercept=False')\n",
    "    x_log = ident_log_scale(x)\n",
    "    y_log = ident_log_scale(y)\n",
    "    y2_log = ident_log_scale(y2)\n",
    "    if x_log:\n",
    "        plt.xscale(\"log\")\n",
    "    if y_log or y2_log:\n",
    "        plt.yscale(\"log\")\n",
    "    plt.title('')\n",
    "    plt.xlabel('positive')\n",
    "    plt.ylabel('score')\n",
    "    plt.legend(loc='center left')\n",
    "\n",
    "    plt.suptitle(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Implementation - Hyperparameter tuning\n",
    "# ----------------------------------------------------------------------========\n",
    "# Proceed for searching searching method for Neighbors Regressor\n",
    "# Build the dictionary of appropriate refined dataframes\n",
    "\n",
    "dfs = {'hosp': {'Department 31': df_D31_hosp_NeiReg,\n",
    "                'Region 76': df_R76_hosp_NeiReg,\n",
    "                'France': df_Fr_hosp_NeiReg\n",
    "               },\n",
    "       'rea': {'Department 31': df_D31_rea_NeiReg,\n",
    "                'Region 76': df_R76_rea_NeiReg,\n",
    "                'France': df_Fr_rea_NeiReg\n",
    "              }\n",
    "      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Implementation - Hyperparameter tuning\n",
    "# ----------------------------------------------------------------------========\n",
    "# Proceed for searching searching method for Neighbors Regressor\n",
    "# Apply for target 'hosp' at department level\n",
    "\n",
    "target = 'hosp'\n",
    "area = 'Department 31'\n",
    "param_study_NeighborReg(dfs, target, area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Implementation - Hyperparameter tuning\n",
    "# ----------------------------------------------------------------------========\n",
    "# Proceed for searching searching method for Neighbors Regressor\n",
    "# Apply for target 'hosp' at region level\n",
    "\n",
    "target = 'hosp'\n",
    "area = 'Region 76'\n",
    "param_study_NeighborReg(dfs, target, area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Implementation - Hyperparameter tuning\n",
    "# ----------------------------------------------------------------------========\n",
    "# Proceed for searching searching method for Neighbors Regressor\n",
    "# Apply for target 'hosp' at Country level\n",
    "\n",
    "target = 'hosp'\n",
    "area = 'France'\n",
    "param_study_NeighborReg(dfs, target, area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Implementation - Hyperparameter tuning\n",
    "# ----------------------------------------------------------------------========\n",
    "# Proceed for searching searching method for Neighbors Regressor\n",
    "# Apply for target 'rea' at department level\n",
    "\n",
    "target = 'rea'\n",
    "area = 'Department 31'\n",
    "param_study_NeighborReg(dfs, target, area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Implementation - Hyperparameter tuning\n",
    "# ----------------------------------------------------------------------========\n",
    "# Proceed for searching searching method for Neighbors Regressor\n",
    "# Apply for target 'rea' at Region level\n",
    "\n",
    "target = 'rea'\n",
    "area = 'Region 76'\n",
    "param_study_NeighborReg(dfs, target, area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Implementation - Hyperparameter tuning\n",
    "# ----------------------------------------------------------------------========\n",
    "# Proceed for searching searching method for Neighbors Regressor\n",
    "# Apply for target 'rea' at Region level\n",
    "\n",
    "target = 'rea'\n",
    "area = 'France'\n",
    "# param_study_NeighborReg(dfs, target, area)\n",
    "# Cancelled because it run 26min 0.5s without display neither plot nor error or warning message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Implementation - Hyperparameter tuning\n",
    "# ----------------------------------------------------------------------========\n",
    "# Proceed for searching searching method for Linear Regressor\n",
    "# Apply for target 'hosp' at department level\n",
    "\n",
    "target = 'hosp'\n",
    "area = 'Department 31'\n",
    "param_study_LinearReg(dfs, target, area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Implementation - Hyperparameter tuning\n",
    "# ----------------------------------------------------------------------========\n",
    "# Proceed for searching searching method for Linear Regressor\n",
    "# Apply for target 'hosp' at region level\n",
    "\n",
    "target = 'hosp'\n",
    "area = 'Region 76'\n",
    "param_study_LinearReg(dfs, target, area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Implementation - Hyperparameter tuning\n",
    "# ----------------------------------------------------------------------========\n",
    "# Proceed for searching searching method for Linear Regressor\n",
    "# Apply for target 'hosp' at country level\n",
    "\n",
    "target = 'hosp'\n",
    "area = 'France'\n",
    "param_study_LinearReg(dfs, target, area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Implementation - Hyperparameter tuning\n",
    "# ----------------------------------------------------------------------========\n",
    "# Proceed for searching searching method for Linear Regressor\n",
    "# Apply for target 'rea' at department level\n",
    "\n",
    "target = 'rea'\n",
    "area = 'Department 31'\n",
    "param_study_LinearReg(dfs, target, area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Implementation - Hyperparameter tuning\n",
    "# ----------------------------------------------------------------------========\n",
    "# Proceed for searching searching method for Linear Regressor\n",
    "# Apply for target 'rea' at region level\n",
    "\n",
    "target = 'rea'\n",
    "area = 'Region 76'\n",
    "param_study_LinearReg(dfs, target, area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Implementation - Hyperparameter tuning\n",
    "# ----------------------------------------------------------------------========\n",
    "# Proceed for searching searching method for Linear Regressor\n",
    "# Apply for target 'rea' at country level\n",
    "\n",
    "target = 'rea'\n",
    "area = 'France'\n",
    "param_study_LinearReg(dfs, target, area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Implementation - Hyperparameter tuning\n",
    "# ----------------------------------------------------------------------========\n",
    "# Proceed for searching searching method for Linear Regressor\n",
    "# Apply for target 'hosp' at department level\n",
    "\n",
    "target = 'hosp'\n",
    "area = 'Department 31'\n",
    "param_study_LinearRidge(dfs, target, area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Implementation - Hyperparameter tuning\n",
    "# ----------------------------------------------------------------------========\n",
    "# Proceed for searching searching method for Linear Regressor\n",
    "# Apply for target 'hosp' at region level\n",
    "\n",
    "target = 'hosp'\n",
    "area = 'Region 76'\n",
    "param_study_LinearRidge(dfs, target, area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Implementation - Hyperparameter tuning\n",
    "# ----------------------------------------------------------------------========\n",
    "# Proceed for searching searching method for Linear Regressor\n",
    "# Apply for target 'hosp' at country level\n",
    "\n",
    "target = 'hosp'\n",
    "area = 'France'\n",
    "param_study_LinearRidge(dfs, target, area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Implementation - Hyperparameter tuning\n",
    "# ----------------------------------------------------------------------========\n",
    "# Proceed for searching searching method for Linear Regressor\n",
    "# Apply for target 'rea' at department level\n",
    "\n",
    "target = 'rea'\n",
    "area = 'Department 31'\n",
    "param_study_LinearRidge(dfs, target, area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Implementation - Hyperparameter tuning\n",
    "# ----------------------------------------------------------------------========\n",
    "# Proceed for searching searching method for Linear Regressor\n",
    "# Apply for target 'rea' at region level\n",
    "\n",
    "target = 'rea'\n",
    "area = 'Region 76'\n",
    "param_study_LinearRidge(dfs, target, area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Implementation - Hyperparameter tuning\n",
    "# ----------------------------------------------------------------------========\n",
    "# Proceed for searching searching method for Linear Regressor\n",
    "# Apply for target 'hosp' at country level\n",
    "\n",
    "target = 'rea'\n",
    "area = 'France'\n",
    "param_study_LinearRidge(dfs, target, area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Vizualization\n",
    "# ----------------------------------------------------------------------========\n",
    "# Create a function to vizualize result on plots\n",
    "\n",
    "def display_results(df, x_name, y_name, graph_title,\n",
    "                    subtitle1='', subtitle2=''):\n",
    "\n",
    "    plt.figure(figsize=(20, 18))\n",
    "\n",
    "    plt.subplot(3, 1, 1)\n",
    "    x = df[x_name]\n",
    "    y = df[y_name]\n",
    "    plt.scatter(x, y, c='g', marker='o')\n",
    "    plt.title('(' + subtitle1 + ' ; ' + subtitle2 + ')')\n",
    "    plt.xlabel(x_name)\n",
    "    plt.ylabel(y_name)\n",
    "    plt.grid(color = 'grey', linestyle = '--', linewidth = 0.5)\n",
    "\n",
    "    plt.subplot(3, 1, 2)\n",
    "    x = df[x_name]\n",
    "    abs_error = np.subtract(y, x)\n",
    "    rel_error = np.divide(abs_error, x)\n",
    "    mini = np.min(rel_error)\n",
    "    maxi = np.max(rel_error)\n",
    "    mean = np.mean(rel_error)\n",
    "    quantile = np.quantile(rel_error, 0.95)\n",
    "    plt.scatter(x, rel_error, c='r', marker='s')\n",
    "    msg1 = str(mini)[:5] + '% (min) ; '\n",
    "    msg2 = str(maxi)[:5] + '% (max) ; '\n",
    "    msg3 = str(mean)[:5] + '% (mean) ;'\n",
    "    msg4 = str(quantile)[:5] + '% (95%-quantile)'\n",
    "    msgA = 'Rel. error: ' + msg1 + msg2 + msg3 + msg4\n",
    "    mini = np.min(abs_error)\n",
    "    maxi = np.max(abs_error)\n",
    "    mean = np.mean(abs_error)\n",
    "    quantile = np.quantile(abs_error, 0.95)\n",
    "    msg1 = str(mini)[:5] + ' (min) ; '\n",
    "    msg2 = str(maxi)[:5] + ' (max) ; '\n",
    "    msg3 = str(mean)[:5] + ' (mean) ;'\n",
    "    msg4 = str(quantile)[:5] + ' (95%-quantile)'\n",
    "    msgB = 'Abs. error: ' + msg1 + msg2 + msg3 + msg4\n",
    "    plt.title(msgA + ' / '+ msgB)\n",
    "    plt.xlabel(x_name)\n",
    "    plt.ylabel('relative error (%)')\n",
    "    plt.grid(color = 'grey', linestyle = '--', linewidth = 0.5)\n",
    "    #plt.yscale(value=\"log\")\n",
    "\n",
    "    try:\n",
    "        plt.subplot(3, 1, 3)\n",
    "        bins_nb = int(pd.DataFrame(rel_error).nunique() / 15)\n",
    "        plt.hist(rel_error, bins=bins_nb, density=True)\n",
    "        plt.title(\"Distribution of the relative error values\" + sb)\n",
    "        plt.xlabel('relative error (%)')\n",
    "        plt.ylabel('density')\n",
    "    except:\n",
    "        print(\"Distribution ploting failure\")\n",
    "\n",
    "    plt.suptitle(graph_title, y=0.92)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Vizualization\n",
    "# ----------------------------------------------------------------------========\n",
    "# Define the function to build, train, fit and use the model  \n",
    "\n",
    "def main(df, target, title):\n",
    "\n",
    "    df_mdl = df.copy(deep=True)\n",
    "\n",
    "    # split data set\n",
    "    testrate = 0.3\n",
    "    X, y = get_X_y(df_mdl, target)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                    test_size=testrate,\n",
    "                                    random_state=42)\n",
    "\n",
    "    # build model\n",
    "    model = neighbors.KNeighborsRegressor(weights='distance',\n",
    "                                          p=1,\n",
    "                                          n_neighbors=4)\n",
    "    #                                     n_neighbors=500,\n",
    "    #                                     n_jobs=4)\n",
    "        \n",
    "    # train model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # predict on test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "   # Scoring\n",
    "    try:\n",
    "        r2_score_value = r2_score(y, model.predict(X))\n",
    "    except:\n",
    "        r2_score_value = None\n",
    "    try:\n",
    "        score_value = model.score(X_test, y_test)\n",
    "    except:\n",
    "        score_value = None\n",
    "    # print('r2 score     :', r2_score_value)\n",
    "    # print(\"Model's score:\", score_value)\n",
    "\n",
    "    # display results\n",
    "    display_results(pd.DataFrame({'y_test': y_test.tolist(), 'y_pred': y_pred.tolist()}),\n",
    "                    'y_test', 'y_pred',\n",
    "                    'Predictions vs True values - ' + title,\n",
    "                    subtitle1='R2 score = ' + str(r2_score_value), subtitle2='score = ' + str(score_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Vizualization\n",
    "# ----------------------------------------------------------------------========\n",
    "main(df_D31_hosp_NeiReg, 'hosp', \"Number of hospitalization in the department 31 (Neighbors Regressor method)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Vizualization\n",
    "# ----------------------------------------------------------------------========\n",
    "main(df_D31_rea_NeiReg, 'rea', \"Number of people in resuscitation in the department 31 (Neighbors Regressor method)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Vizualization\n",
    "# ----------------------------------------------------------------------========\n",
    "main(df_R76_hosp_NeiReg, 'hosp', \"Number of hospitalization in the Region 76 (Neighbors Regressor method)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Vizualization\n",
    "# ----------------------------------------------------------------------========\n",
    "main(df_R76_rea_NeiReg, 'rea', \"Number of people in resuscitation in the Region 76 (Neighbors Regressor method)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Vizualization\n",
    "# ----------------------------------------------------------------------========\n",
    "main(df_Fr_hosp_NeiReg, 'hosp', \"Number of hospitalization in France (Neighbors Regressor method)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Vizualization\n",
    "# ----------------------------------------------------------------------========\n",
    "main(df_Fr_rea_NeiReg, 'rea', \"Number of people in resuscitation in France (Neighbors Regressor method)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Vizualization\n",
    "# ----------------------------------------------------------------------========\n",
    "# Define the function to build, train, fit and use the model\n",
    "# Compare with Linear Regression model\n",
    "\n",
    "def main2(df, target, title):\n",
    "\n",
    "    df_mdl = df.copy(deep=True)\n",
    "\n",
    "    # split data set\n",
    "    testrate = 0.3\n",
    "    X, y = get_X_y(df_mdl, target)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                    test_size=testrate,\n",
    "                                    random_state=42)\n",
    "\n",
    "    # build model\n",
    "    model = LinearRegression(positive=True, fit_intercept=False)\n",
    "        \n",
    "    # train model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # predict on test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "   # Scoring\n",
    "    try:\n",
    "        r2_score_value = r2_score(y, model.predict(X))\n",
    "    except:\n",
    "        r2_score_value = None\n",
    "    try:\n",
    "        score_value = model.score(X_test, y_test)\n",
    "    except:\n",
    "        score_value = None\n",
    "    # print('r2 score     :', r2_score_value)\n",
    "    # print(\"Model's score:\", score_value)\n",
    "\n",
    "    # display results\n",
    "    display_results(pd.DataFrame({'y_test': y_test.tolist(), 'y_pred': y_pred.tolist()}),\n",
    "                    'y_test', 'y_pred',\n",
    "                    'Predictions vs True values - ' + title,\n",
    "                    subtitle1='R2 score = ' + str(r2_score_value), subtitle2='score = ' + str(score_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Vizualization\n",
    "# ----------------------------------------------------------------------========\n",
    "main2(df_D31_hosp_LinReg, 'hosp', \"Number of hospitalization in the department 31 (LinearRegression method)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Vizualization\n",
    "# ----------------------------------------------------------------------========\n",
    "main2(df_D31_rea_LinReg, 'rea', \"Number of people in resuscitation in the department 31 (LinearRegression method)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Vizualization\n",
    "# ----------------------------------------------------------------------========\n",
    "main2(df_R76_hosp_LinReg, 'hosp', \"Number of hospitalization in the Region 76 (LinearRegression method)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Vizualization\n",
    "# ----------------------------------------------------------------------========\n",
    "main2(df_R76_rea_LinReg, 'rea', \"Number of people in resuscitation in the Region 76 (LinearRegression method)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Vizualization\n",
    "# ----------------------------------------------------------------------========\n",
    "main2(df_Fr_hosp_LinReg, 'hosp', \"Number of hospitalization in France (LinearRegression method)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Vizualization\n",
    "# ----------------------------------------------------------------------========\n",
    "main2(df_Fr_rea_LinReg, 'rea', \"Number of people in resuscitation in France (LinearRegression method)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Vizualization\n",
    "# ----------------------------------------------------------------------========\n",
    "# Define the function to build, train, fit and use the model\n",
    "# Compare with Linear Ridge model\n",
    "\n",
    "def main3(df, target, title):\n",
    "\n",
    "    df_mdl = df.copy(deep=True)\n",
    "\n",
    "    # split data set\n",
    "    testrate = 0.3\n",
    "    X, y = get_X_y(df_mdl, target)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                    test_size=testrate,\n",
    "                                    random_state=42)\n",
    "\n",
    "    # build model\n",
    "    model = Ridge(fit_intercept=True,\n",
    "                  alpha=20,\n",
    "                  positive=False,\n",
    "                  max_iter=900,\n",
    "                  tol=10)\n",
    "\n",
    "    # train model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # predict on test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "   # Scoring\n",
    "    try:\n",
    "        r2_score_value = r2_score(y, model.predict(X))\n",
    "    except:\n",
    "        r2_score_value = None\n",
    "    try:\n",
    "        score_value = model.score(X_test, y_test)\n",
    "    except:\n",
    "        score_value = None\n",
    "    # print('r2 score     :', r2_score_value)\n",
    "    # print(\"Model's score:\", score_value)\n",
    "\n",
    "    # display results\n",
    "    display_results(pd.DataFrame({'y_test': y_test.tolist(), 'y_pred': y_pred.tolist()}),\n",
    "                    'y_test', 'y_pred',\n",
    "                    'Predictions vs True values - ' + title,\n",
    "                    subtitle1='R2 score = ' + str(r2_score_value), subtitle2='score = ' + str(score_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Vizualization\n",
    "# ----------------------------------------------------------------------========\n",
    "main3(df_D31_hosp_LinRid, 'hosp', \"Number of hospitalization in the department 31 (Linear Ridge method)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Vizualization\n",
    "# ----------------------------------------------------------------------========\n",
    "main3(df_D31_rea_LinRid, 'rea', \"Number of people in resuscitation in the department 31 (Linear Ridge method)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Vizualization\n",
    "# ----------------------------------------------------------------------========\n",
    "main3(df_R76_hosp_LinRid, 'hosp', \"Number of hospitalization in the Region 76 (Linear Ridge method)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Vizualization\n",
    "# ----------------------------------------------------------------------========\n",
    "main3(df_R76_rea_LinRid, 'rea', \"Number of people in resuscitation in the Region 76 (Linear Ridge method)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Vizualization\n",
    "# ----------------------------------------------------------------------========\n",
    "main3(df_Fr_hosp_LinRid, 'hosp', \"Number of hospitalization in France (Linear Ridge method)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODOLOGY - Vizualization\n",
    "# ----------------------------------------------------------------------========\n",
    "main3(df_Fr_rea_LinRid, 'rea', \"Number of people in resuscitation in France (Linear Ridge method)\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0600588c3b5f4418cbe7b5ebc6825b479f3bc010269d8b60d75058cdd010adfe"
  },
  "kernelspec": {
   "display_name": "Python 3.7.8 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
